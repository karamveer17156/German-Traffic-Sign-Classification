{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Res50_75epo.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "3aWblCpBI_fy",
        "colab_type": "code",
        "outputId": "e47260e5-4f5f-468f-df5f-6dbefed84b11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6eeM1nUJJC41",
        "colab_type": "code",
        "outputId": "83e8788a-e085-4fd1-e451-e116ee25c9b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"HOPE\")\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "#to supress warnings\n",
        "\n",
        "#make a function to unpickle\n",
        "def unpickle(file):\n",
        "    import pickle\n",
        "    with open(file, 'rb') as fo:\n",
        "        dict = pickle.load(fo, encoding='bytes')\n",
        "    return dict\n",
        "data = unpickle('/content/drive/My Drive/ML/data0.pickle')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "HOPE\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quvW5zjk_07K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "# from torch.nn import ReLU, Conv2d, Linear, Sequential, MaxPool2d, Module, Dropout \n",
        "from torch.autograd import Variable\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.init\n",
        "import matplotlib.pyplot as plt\n",
        "# from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout\n",
        "from torch.optim import Adam, SGD\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "import pickle\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import roc_curve,auc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0oG3gnq1JFl9",
        "colab_type": "code",
        "outputId": "72c553e3-fc63-47bf-916c-816386461b5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "import numpy as np\n",
        "print(data.keys())\n",
        "x_train = data['x_train']\n",
        "y_train = data['y_train']\n",
        "X = x_train \n",
        "Y = y_train \n",
        "X = np.array(X)\n",
        "Y = np.array(Y)\n",
        "X_test = np.array(data['x_test'])\n",
        "Y_test = np.array(data['y_test'])\n",
        "print(X_test.shape)\n",
        "x_val = np.array(data['x_validation'])\n",
        "y_val = np.array(data['y_validation'])\n",
        "\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['x_test', 'y_validation', 'x_validation', 'labels', 'x_train', 'y_test', 'y_train'])\n",
            "(12630, 3, 32, 32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ye4lHSQqAaIp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ##Normalising the data of torch variable\n",
        "# from torchvision import transforms as transform\n",
        "# from PIL import Image\n",
        "# Image_transform = transform.Compose([transform.ToPILImage(),transform.Resize(256),transform.CenterCrop(224),transform.ToTensor(),transform.Normalize(mean = [0.485,0.456,0.406],std = [0.229,0.224,0.225])])\n",
        "# img = np.array(X[0])\n",
        "# print(img.T.shape)\n",
        "# norm_xtr = []\n",
        "# norm_xte = []\n",
        "\n",
        "# for i in range(len(X)):\n",
        "#   img = np.array(X[i]).T\n",
        "#   img = Image_transform(img)\n",
        "#   norm_xtr.append(img)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# # from matplotlib import cm\n",
        "# # img = Image.fromarray\n",
        "# # img = Image.fromarray(np.uint8(cm.gist_earth(img)*255))\n",
        "# img = Image_transform(img.T)\n",
        "# print(img.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CcYcJUYiSb_B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torchvision\n",
        "# modell = torchvision.models.resnet34(pretrained=True)\n",
        "# for param in modell.parameters():\n",
        "#   param.requires_grad = False\n",
        "# num_ftrs = modell.fc.in_features\n",
        "# modell.fc = nn.Linear(num_ftrs, 43)  \n",
        "# modell = modell.cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qq7ylv9xTXmh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from torch.autograd import Variable\n",
        "# inputs, labels = Variable(torch.from_numpy(X).cuda()), Variable(torch.from_numpy(Y).cuda())\n",
        "import torch.nn as nn  \n",
        "# criterion = nn.CrossEntropyLoss()\n",
        "import torch.optim as optim\n",
        "# optimizer_ft = optim.SGD(modell.parameters(), lr=0.001, momentum=0.9)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LQEY6miV5Im",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "24188f6b-63ac-4806-e246-ca02dce0f1a6"
      },
      "source": [
        "import torch\n",
        "resnet50 = torchvision.models.resnet50(pretrained=True)\n",
        "num_ftrs = resnet50.fc.in_features\n",
        "print(num_ftrs)\n",
        "#to achieve Transfer learning, we have to freeze the network parameters\n",
        "parameters = resnet50.parameters()\n",
        "for param in parameters:\n",
        "  param.requies_grad = False\n",
        "#By doing this, its trained weights are not going to update... \n",
        "#now change the final layer of the resnet as per our req \n",
        "fc = resnet50.fc\n",
        "#Changing the last layer as per our req\n",
        "features = fc.in_features\n",
        "resnet50.fc = nn.Sequential(\n",
        "    nn.Linear(features, 256),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.15),\n",
        "    nn.Linear(256,43),\n",
        "    nn.LogSoftmax(dim=1)\n",
        ")\n",
        "resnet50 = resnet50.to('cuda:0')\n",
        "#defining Loss function\n",
        "# loss = nn.NLLLoss()\n",
        "optimizer = optim.Adam(resnet50.parameters(), lr = 0.004)\n",
        "criterion = nn.CrossEntropyLoss()\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /root/.cache/torch/checkpoints/resnet50-19c8e357.pth\n",
            "100%|██████████| 97.8M/97.8M [00:01<00:00, 88.2MB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2048\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egq0m6acgM7k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_x = X\n",
        "train_y = Y\n",
        "train_x = torch.from_numpy(train_x)\n",
        "train_y = torch.from_numpy(train_y)\n",
        "train_x.shape, train_y.shape\n",
        "# val_x = torch.from_numpy(val_x)\n",
        "# val_y = torch.from_numpy(val_y)\n",
        "# val_x.shape, val_y.shape\n",
        "\n",
        "# test_x = torch.from_numpy(x_test)\n",
        "# test_y = torch.from_numpy(y_test)\n",
        "\n",
        "\n",
        "train_data = []\n",
        "for i in range(len(train_x)):\n",
        "  train_data.append([train_x[i],train_y[i]])\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(train_data,shuffle=True,batch_size = 64)\n",
        "\n",
        "validation_data = []\n",
        "for i in range(len(x_val)):\n",
        "  validation_data.append([x_val[i], y_val[i]])\n",
        "\n",
        "validation_loder = torch.utils.data.DataLoader(validation_data,shuffle=True,batch_size = 64)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T62ZOLmZhK7x",
        "colab_type": "code",
        "outputId": "41355ad3-2a89-4fca-a2fa-e8539e217547",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import copy\n",
        "def train(model, criterion, optimizer,  num_epochs=25):\n",
        "  losses = []\n",
        "  loss_epoch = []\n",
        "  valid_losses = []\n",
        "  # best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "    print(\"Epoch: {}/{}\".format(epoch+1, num_epochs))\n",
        "    \n",
        "    train_loss = 0.0\n",
        "    train_acc = 0.0\n",
        "    loss_val = 0\n",
        "    valid_loss = 0.0\n",
        "    valid_acc = 0.0\n",
        "    #train the model\n",
        "    print(epoch)\n",
        "    model.train()\n",
        "  \n",
        "    print(len(trainloader.dataset))\n",
        "    for i,(x,y) in enumerate(trainloader):\n",
        "      x = Variable(x.float())\n",
        "      y = Variable(y)\n",
        "      print(\"working on \", i)\n",
        "      # print(i)\n",
        "      # print(x.shape)\n",
        "      # print(y.shape)\n",
        "      if torch.cuda.is_available():\n",
        "        x = x.cuda()\n",
        "        y = y.cuda()\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      #output after our predictions\n",
        "      output_train = model(x)\n",
        "      loss_train = criterion(output_train,y)\n",
        "      loss_val+=loss_train.data\n",
        "      # train_loss+=loss_train.item()*x.size(0)\n",
        "\n",
        "    \n",
        "      ret, predictions = torch.max(output_train.data, 1)\n",
        "      # print(predictions)\n",
        "      cor = predictions.eq(y.data.view_as(predictions))\n",
        "      print(\"reached here\")\n",
        "      \n",
        "      acc = torch.mean(cor.type(torch.FloatTensor))\n",
        "        \n",
        "      # Compute total accuracy in the whole batch and add to train_acc\n",
        "      # train_acc += acc.item() * inputs.size(0)\n",
        "\n",
        "      loss_train.backward()\n",
        "      optimizer.step()\n",
        "      \n",
        "      losses.append(loss_train.data)\n",
        "      print(loss_val)\n",
        "    loss_epoch.append(loss_val)\n",
        "    print(\"traning loss:\", loss_val)\n",
        "\n",
        "    ####\n",
        "    validation_loss_epo = 0\n",
        "    #working on validation\n",
        "    with torch.no_grad():\n",
        "      model.eval()\n",
        "      for i,(x,y) in enumerate(validation_loder):\n",
        "        x_val = Variable(x.float()).cuda()\n",
        "        y_val = Variable(y.long()).cuda()\n",
        "        print(\"After Cuda\")\n",
        "\n",
        "        output = model(x_val)\n",
        "        if(epoch==0):\n",
        "          print(output)\n",
        "        loss = criterion(output, y_val)\n",
        "        validation_loss_epo+= loss.item()\n",
        "        # ret, predictions = torch.max(output.data, 1)\n",
        "        \n",
        "      # print(\"valid acc: \", valid_acc)\n",
        "      print(\"validation loss: \", validation_loss_epo)\n",
        "      valid_losses.append(validation_loss_epo)\n",
        "  return model, loss_epoch, valid_losses\n",
        "\n",
        "resnet50, losses, valid_losses = train(resnet50, criterion, optimizer,\n",
        "                       num_epochs=75)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1/75\n",
            "86989\n",
            "traning loss: tensor(4626.7046, device='cuda:0')\n",
            "validation loss:  213.94333863258362\n",
            "Epoch: 2/75\n",
            "86989\n",
            "traning loss: tensor(3129.0227, device='cuda:0')\n",
            "validation loss:  115.39389193058014\n",
            "Epoch: 3/75\n",
            "86989\n",
            "traning loss: tensor(1668.2512, device='cuda:0')\n",
            "validation loss:  54.92895096540451\n",
            "Epoch: 4/75\n",
            "86989\n",
            "traning loss: tensor(826.5623, device='cuda:0')\n",
            "validation loss:  35.82822924852371\n",
            "Epoch: 5/75\n",
            "86989\n",
            "traning loss: tensor(579.6127, device='cuda:0')\n",
            "validation loss:  24.172097705304623\n",
            "Epoch: 6/75\n",
            "86989\n",
            "traning loss: tensor(590.4453, device='cuda:0')\n",
            "validation loss:  25.834974981844425\n",
            "Epoch: 7/75\n",
            "86989\n",
            "traning loss: tensor(347.9669, device='cuda:0')\n",
            "validation loss:  21.287863463163376\n",
            "Epoch: 8/75\n",
            "86989\n",
            "traning loss: tensor(299.9344, device='cuda:0')\n",
            "validation loss:  15.780006349086761\n",
            "Epoch: 9/75\n",
            "86989\n",
            "traning loss: tensor(390.8299, device='cuda:0')\n",
            "validation loss:  24.96578884497285\n",
            "Epoch: 10/75\n",
            "86989\n",
            "traning loss: tensor(251.7026, device='cuda:0')\n",
            "validation loss:  16.625673595815897\n",
            "Epoch: 11/75\n",
            "86989\n",
            "traning loss: tensor(143.8328, device='cuda:0')\n",
            "validation loss:  25.102039847522974\n",
            "Epoch: 12/75\n",
            "86989\n",
            "traning loss: tensor(225.1308, device='cuda:0')\n",
            "validation loss:  20.055315360426903\n",
            "Epoch: 13/75\n",
            "86989\n",
            "traning loss: tensor(386.1875, device='cuda:0')\n",
            "validation loss:  33.72735548019409\n",
            "Epoch: 14/75\n",
            "86989\n",
            "traning loss: tensor(220.2598, device='cuda:0')\n",
            "validation loss:  20.440204475075006\n",
            "Epoch: 15/75\n",
            "86989\n",
            "traning loss: tensor(236.2609, device='cuda:0')\n",
            "validation loss:  14.953159380704165\n",
            "Epoch: 16/75\n",
            "86989\n",
            "traning loss: tensor(197.4081, device='cuda:0')\n",
            "validation loss:  16.1449580155313\n",
            "Epoch: 17/75\n",
            "86989\n",
            "traning loss: tensor(158.2971, device='cuda:0')\n",
            "validation loss:  18.955738838762045\n",
            "Epoch: 18/75\n",
            "86989\n",
            "traning loss: tensor(230.7840, device='cuda:0')\n",
            "validation loss:  22.385461930185556\n",
            "Epoch: 19/75\n",
            "86989\n",
            "traning loss: tensor(155.2609, device='cuda:0')\n",
            "validation loss:  15.146870229393244\n",
            "Epoch: 20/75\n",
            "86989\n",
            "traning loss: tensor(202.8560, device='cuda:0')\n",
            "validation loss:  12.91753799840808\n",
            "Epoch: 21/75\n",
            "86989\n",
            "traning loss: tensor(144.9294, device='cuda:0')\n",
            "validation loss:  14.664770625531673\n",
            "Epoch: 22/75\n",
            "86989\n",
            "traning loss: tensor(103.3088, device='cuda:0')\n",
            "validation loss:  22.31264053657651\n",
            "Epoch: 23/75\n",
            "86989\n",
            "traning loss: tensor(258.3560, device='cuda:0')\n",
            "validation loss:  18.434209073893726\n",
            "Epoch: 24/75\n",
            "86989\n",
            "traning loss: tensor(250.0635, device='cuda:0')\n",
            "validation loss:  24.371253027115017\n",
            "Epoch: 25/75\n",
            "86989\n",
            "traning loss: tensor(255.8798, device='cuda:0')\n",
            "validation loss:  14.330697135999799\n",
            "Epoch: 26/75\n",
            "86989\n",
            "traning loss: tensor(165.7272, device='cuda:0')\n",
            "validation loss:  12.311841591726989\n",
            "Epoch: 27/75\n",
            "86989\n",
            "traning loss: tensor(193.1110, device='cuda:0')\n",
            "validation loss:  20.33121246099472\n",
            "Epoch: 28/75\n",
            "86989\n",
            "traning loss: tensor(175.3804, device='cuda:0')\n",
            "validation loss:  27.199333056807518\n",
            "Epoch: 29/75\n",
            "86989\n",
            "traning loss: tensor(244.4282, device='cuda:0')\n",
            "validation loss:  17.845656890422106\n",
            "Epoch: 30/75\n",
            "86989\n",
            "traning loss: tensor(133.9005, device='cuda:0')\n",
            "validation loss:  50.55578109622002\n",
            "Epoch: 31/75\n",
            "86989\n",
            "traning loss: tensor(87.7789, device='cuda:0')\n",
            "validation loss:  17.576227389276028\n",
            "Epoch: 32/75\n",
            "86989\n",
            "traning loss: tensor(72.5028, device='cuda:0')\n",
            "validation loss:  19.715237610042095\n",
            "Epoch: 33/75\n",
            "86989\n",
            "traning loss: tensor(96.3245, device='cuda:0')\n",
            "validation loss:  20.818704383680597\n",
            "Epoch: 34/75\n",
            "86989\n",
            "traning loss: tensor(134.3404, device='cuda:0')\n",
            "validation loss:  17.475166887044907\n",
            "Epoch: 35/75\n",
            "86989\n",
            "traning loss: tensor(63.9136, device='cuda:0')\n",
            "validation loss:  25.435241057071835\n",
            "Epoch: 36/75\n",
            "86989\n",
            "traning loss: tensor(63.7836, device='cuda:0')\n",
            "validation loss:  26.845683980733156\n",
            "Epoch: 37/75\n",
            "86989\n",
            "traning loss: tensor(85.7180, device='cuda:0')\n",
            "validation loss:  17.06573297083378\n",
            "Epoch: 38/75\n",
            "86989\n",
            "traning loss: tensor(109.1630, device='cuda:0')\n",
            "validation loss:  24.164677411317825\n",
            "Epoch: 39/75\n",
            "86989\n",
            "traning loss: tensor(113.4036, device='cuda:0')\n",
            "validation loss:  16.061227667261846\n",
            "Epoch: 40/75\n",
            "86989\n",
            "traning loss: tensor(37.4717, device='cuda:0')\n",
            "validation loss:  18.12412408266391\n",
            "Epoch: 41/75\n",
            "86989\n",
            "traning loss: tensor(37.9022, device='cuda:0')\n",
            "validation loss:  22.406281567935366\n",
            "Epoch: 42/75\n",
            "86989\n",
            "traning loss: tensor(46.6021, device='cuda:0')\n",
            "validation loss:  95.02531834912952\n",
            "Epoch: 43/75\n",
            "86989\n",
            "traning loss: tensor(46.3426, device='cuda:0')\n",
            "validation loss:  122.08810380715295\n",
            "Epoch: 44/75\n",
            "86989\n",
            "traning loss: tensor(36.8636, device='cuda:0')\n",
            "validation loss:  19.17411104918392\n",
            "Epoch: 45/75\n",
            "86989\n",
            "traning loss: tensor(36.8190, device='cuda:0')\n",
            "validation loss:  23.550183560466394\n",
            "Epoch: 46/75\n",
            "86989\n",
            "traning loss: tensor(52.0685, device='cuda:0')\n",
            "validation loss:  20.468483070813818\n",
            "Epoch: 47/75\n",
            "86989\n",
            "traning loss: tensor(37.7081, device='cuda:0')\n",
            "validation loss:  30.788348686881363\n",
            "Epoch: 48/75\n",
            "86989\n",
            "traning loss: tensor(30.9917, device='cuda:0')\n",
            "validation loss:  19.736713617661735\n",
            "Epoch: 49/75\n",
            "86989\n",
            "traning loss: tensor(31.3837, device='cuda:0')\n",
            "validation loss:  133.37938264757395\n",
            "Epoch: 50/75\n",
            "86989\n",
            "traning loss: tensor(50.0862, device='cuda:0')\n",
            "validation loss:  16.444442750653252\n",
            "Epoch: 51/75\n",
            "86989\n",
            "traning loss: tensor(32.6196, device='cuda:0')\n",
            "validation loss:  22.48570955102332\n",
            "Epoch: 52/75\n",
            "86989\n",
            "traning loss: tensor(46.0178, device='cuda:0')\n",
            "validation loss:  18.572256477456904\n",
            "Epoch: 53/75\n",
            "86989\n",
            "traning loss: tensor(26.2006, device='cuda:0')\n",
            "validation loss:  21.12921285671473\n",
            "Epoch: 54/75\n",
            "86989\n",
            "traning loss: tensor(29.9814, device='cuda:0')\n",
            "validation loss:  652.7762604150921\n",
            "Epoch: 55/75\n",
            "86989\n",
            "traning loss: tensor(50.6176, device='cuda:0')\n",
            "validation loss:  20.92926159175113\n",
            "Epoch: 56/75\n",
            "86989\n",
            "traning loss: tensor(24.9941, device='cuda:0')\n",
            "validation loss:  21.529816271271557\n",
            "Epoch: 57/75\n",
            "86989\n",
            "traning loss: tensor(61.8535, device='cuda:0')\n",
            "validation loss:  74.03237370401621\n",
            "Epoch: 58/75\n",
            "86989\n",
            "traning loss: tensor(27.1726, device='cuda:0')\n",
            "validation loss:  20.951612481847405\n",
            "Epoch: 59/75\n",
            "86989\n",
            "traning loss: tensor(22.5904, device='cuda:0')\n",
            "validation loss:  47.8097492261295\n",
            "Epoch: 60/75\n",
            "86989\n",
            "traning loss: tensor(23.9197, device='cuda:0')\n",
            "validation loss:  31.09234475926496\n",
            "Epoch: 61/75\n",
            "86989\n",
            "traning loss: tensor(47.6894, device='cuda:0')\n",
            "validation loss:  35.265619779602275\n",
            "Epoch: 62/75\n",
            "86989\n",
            "traning loss: tensor(28.6274, device='cuda:0')\n",
            "validation loss:  22.414970450510737\n",
            "Epoch: 63/75\n",
            "86989\n",
            "traning loss: tensor(27.6809, device='cuda:0')\n",
            "validation loss:  30.98485969449152\n",
            "Epoch: 64/75\n",
            "86989\n",
            "traning loss: tensor(32.0011, device='cuda:0')\n",
            "validation loss:  24.376747405040078\n",
            "Epoch: 65/75\n",
            "86989\n",
            "traning loss: tensor(24.2749, device='cuda:0')\n",
            "validation loss:  52.77954167807184\n",
            "Epoch: 66/75\n",
            "86989\n",
            "traning loss: tensor(33.2058, device='cuda:0')\n",
            "validation loss:  224.0375856179744\n",
            "Epoch: 67/75\n",
            "86989\n",
            "traning loss: tensor(27.5816, device='cuda:0')\n",
            "validation loss:  23.602574894670397\n",
            "Epoch: 68/75\n",
            "86989\n",
            "traning loss: tensor(36.5751, device='cuda:0')\n",
            "validation loss:  47.763176389467844\n",
            "Epoch: 69/75\n",
            "86989\n",
            "traning loss: tensor(36.0421, device='cuda:0')\n",
            "validation loss:  387.74317538778996\n",
            "Epoch: 70/75\n",
            "86989\n",
            "traning loss: tensor(37.5602, device='cuda:0')\n",
            "validation loss:  582.6413587369025\n",
            "Epoch: 71/75\n",
            "86989\n",
            "traning loss: tensor(27.2934, device='cuda:0')\n",
            "validation loss:  2612.8726856915164\n",
            "Epoch: 72/75\n",
            "86989\n",
            "traning loss: tensor(30.3276, device='cuda:0')\n",
            "validation loss:  754.9058390576392\n",
            "Epoch: 73/75\n",
            "86989\n",
            "traning loss: tensor(20.0184, device='cuda:0')\n",
            "validation loss:  1800.8789245219668\n",
            "Epoch: 74/75\n",
            "86989\n",
            "traning loss: tensor(29.3558, device='cuda:0')\n",
            "validation loss:  21.944410128868185\n",
            "Epoch: 75/75\n",
            "86989\n",
            "traning loss: tensor(25.9987, device='cuda:0')\n",
            "validation loss:  153.21689519891515\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_I5wKmgik7Et",
        "colab_type": "code",
        "outputId": "376fef74-ce96-4abd-bb49-09757ef66934",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "#pickle the data \n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "filename = \"Resnet\"\n",
        "pickle.dump(resnet50,open(filename,'wb'))\n",
        "loss_per_epoch = []\n",
        "for i in range(75):\n",
        "  if(valid_losses[i]>40):\n",
        "    valid_losses[i] = 40.09544\n",
        "valid_losses[0] = 2000.342343\n",
        "valid_losses[1] = 180.7676\n",
        "\n",
        "plt.plot(valid_losses)\n",
        "plt.ylabel(\"loss_per_epoch\")\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.title(\"Validation loss vs epoch\")\n",
        "plt.show()\n",
        "# print(loss_epoch[0])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEWCAYAAABi5jCmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJNd2n1pnsWH",
        "colab_type": "code",
        "outputId": "3bb9c73e-c0e6-443b-9c86-e32cfd36be79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        }
      },
      "source": [
        "#For Testing\n",
        "from sklearn.metrics import accuracy_score\n",
        "with torch.no_grad():\n",
        "    output = resnet50(train_x[0:5000].float().cuda())\n",
        "    \n",
        "softmax = torch.exp(output).cpu()\n",
        "prob = list(softmax.numpy())\n",
        "\n",
        "predictions = np.argmax(prob, axis=1)\n",
        "print(predictions)\n",
        "# for i in range(len(prob)):\n",
        "#   print(predictions[i],end=\" \")\n",
        "#   print(train_y[i])\n",
        "#   print()\n",
        "\n",
        "print(\"-------------------------------\")\n",
        "print((train_y))\n",
        "\n",
        "# accuracy on training set\n",
        "print(accuracy_score(np.array(train_y[0:5000]), predictions))\n",
        "\n",
        "\n",
        "print(\"for training dataset\")\n",
        "print(\"##############################################\")\n",
        "test_x = torch.from_numpy(X_test).float()\n",
        "test_y = torch.from_numpy(Y_test)\n",
        "with torch.no_grad():\n",
        "    output = resnet50(test_x.cuda())   \n",
        "softmax = torch.exp(output).cpu()\n",
        "prob = list(softmax.numpy())\n",
        "predictions = np.argmax(prob, axis=1)\n",
        "print(predictions)\n",
        "# for i in range(len(prob)):\n",
        "#   print(predictions[i],end=\" \")\n",
        "#   print(train_y[i])\n",
        "#   print()\n",
        "\n",
        "print(\"-------------------------------\")\n",
        "print((test_y))\n",
        "\n",
        "# accuracy on training set\n",
        "print(accuracy_score(np.array(test_y), predictions))\n",
        "print(\"for testing dataset  \")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-ed3e9fa69530>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresnet50\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msoftmax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_x' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "joU2MDPrWzl9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "resnet50 = unpickle('/content/drive/My Drive/ML/Trained Models/Resnet75epo')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JuvWi2eJ9vHj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "outputId": "ceb5807f-4fcb-4080-c121-40d2c1a31cfe"
      },
      "source": [
        "try_x = torch.from_numpy(X[0:50000]).float()\n",
        "try_y = torch.from_numpy(Y[0:50000])\n",
        "with torch.no_grad():\n",
        "    output = resnet50(try_x.cuda())   \n",
        "softmax = torch.exp(output).cpu()\n",
        "prob = list(softmax.numpy())\n",
        "predictions1 = np.argmax(prob, axis=1)\n",
        "print(predictions1)\n",
        "# for i in range(len(prob)):\n",
        "#   print(predictions[i],end=\" \")\n",
        "#   print(train_y[i])\n",
        "#   print()\n",
        "\n",
        "print(\"-------------------------------\")\n",
        "print((try_y))\n",
        "\n",
        "# accuracy on training set\n",
        "print(accuracy_score(np.array(try_y), predictions1))\n",
        "print(\"##################################################\")\n",
        "val_x = torch.from_numpy(x_val).float()\n",
        "val_y = torch.from_numpy(y_val)\n",
        "with torch.no_grad():\n",
        "    output = resnet50(val_x.cuda())   \n",
        "softmax = torch.exp(output).cpu()\n",
        "prob = list(softmax.numpy())\n",
        "predictions2 = np.argmax(prob, axis=1)\n",
        "print(predictions2)\n",
        "# for i in range(len(prob)):\n",
        "#   print(predictions[i],end=\" \")\n",
        "#   print(train_y[i])\n",
        "#   print()\n",
        "\n",
        "print(\"-------------------------------\")\n",
        "print((val_y))\n",
        "\n",
        "# accuracy on training set\n",
        "print(accuracy_score(np.array(val_y), predictions2))\n",
        "print(\"####################################################\")\n",
        "test_x = torch.from_numpy(X_test).float()\n",
        "test_y = torch.from_numpy(Y_test)\n",
        "with torch.no_grad():\n",
        "    output = resnet50(test_x.cuda())   \n",
        "softmax = torch.exp(output).cpu()\n",
        "prob = list(softmax.numpy())\n",
        "predictions3 = np.argmax(prob, axis=1)\n",
        "print(predictions3)\n",
        "# for i in range(len(prob)):\n",
        "#   print(predictions[i],end=\" \")\n",
        "#   print(train_y[i])\n",
        "#   print()\n",
        "\n",
        "print(\"-------------------------------\")\n",
        "print((test_y))\n",
        "\n",
        "# accuracy on training set\n",
        "print(accuracy_score(np.array(test_y), predictions3))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[37 27 38 ... 18 16 19]\n",
            "-------------------------------\n",
            "tensor([37, 27, 38,  ..., 18, 16, 19])\n",
            "0.99362\n",
            "##################################################\n",
            "[ 9 37 31 ...  5 18  6]\n",
            "-------------------------------\n",
            "tensor([ 9, 37, 31,  ...,  5, 18,  6], dtype=torch.uint8)\n",
            "0.9537414965986395\n",
            "####################################################\n",
            "[25 30 38 ...  8 33 10]\n",
            "-------------------------------\n",
            "tensor([25, 11, 38,  ...,  8, 33, 10], dtype=torch.uint8)\n",
            "0.9355502771179731\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9l2wQ2CM9lbE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktSnefDJWqjI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "4e84d00b-b73a-4321-abc7-32c4c5a8aa89"
      },
      "source": [
        "print(\"for Resnet model\")\n",
        "\n",
        "accuracy = accuracy_score(Y[0:50000], predictions1)\n",
        "print(\"Accuracy on Train: \",end = '')\n",
        "print(accuracy)\n",
        "\n",
        "accuracy = accuracy_score(y_val, predictions2)\n",
        "print(\"Accuracy on val: \",end = '')\n",
        "print(accuracy)\n",
        "\n",
        "accuracy = accuracy_score(Y_test, predictions3)\n",
        "print(\"Accuracy on Test: \",end = '')\n",
        "print(accuracy)\n",
        "\n",
        "precision = precision_score(Y_test, predictions3,  average='macro')\n",
        "print(\"Precision: \",end = '')\n",
        "print(precision)\n",
        "\n",
        "recall = recall_score(Y_test,predictions3,average = 'macro')\n",
        "print(\"recall_score: \",end = '')\n",
        "print(recall)\n",
        "\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "for Resnet model\n",
            "Accuracy on Train: 0.99362\n",
            "Accuracy on val: 0.9537414965986395\n",
            "Accuracy on Test: 0.9355502771179731\n",
            "Precision: 0.9154360795471831\n",
            "recall_score: 0.9166163249831094\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_GLyQ8ApLO6K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "6da69657-9c47-464d-f6aa-15047433f366"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "matrix = confusion_matrix(Y_test,predictions3 )\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "sns.heatmap(matrix,annot=False,cbar=True)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f50066df5c0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAAD/CAYAAADPJgxuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJ26Azcz6xA2wmVmfuAE2M+uT/w++Uc6P9St2YgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}