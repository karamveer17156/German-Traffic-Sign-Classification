# -*- coding: utf-8 -*-
"""CNN_model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1FTymz7_TZJab29xhxOPrTSe7oPcTYnSb
"""

from google.colab import drive


drive.mount('/content/drive')

import numpy as np
import torch
# from torch.nn import ReLU, Conv2d, Linear, Sequential, MaxPool2d, Module, Dropout 
from torch.autograd import Variable
import torchvision.datasets as dsets
import torchvision.transforms as transforms
import torch.nn.init
import matplotlib.pyplot as plt
# from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout
from torch.optim import Adam, SGD
from sklearn.model_selection import train_test_split
from sklearn.neural_network import MLPClassifier
import pickle
from sklearn.metrics import accuracy_score
from sklearn.metrics import f1_score
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
from sklearn.metrics import roc_curve,auc

print("loading file")
import warnings
warnings.filterwarnings("ignore")
#to supress warnings

#make a function to unpickle
def unpickle(file):
    import pickle
    with open(file, 'rb') as fo:
        dict = pickle.load(fo, encoding='bytes')
    return dict
data_gray = unpickle('/content/drive/My Drive/ML/data5.pickle')

print(data_gray.keys())

print(data_gray.keys())
x_train = data_gray['x_train']
y_train = data_gray['y_train']

x_test = np.array(data_gray['x_test'])
y_test = np.array(data_gray['y_test'])

x_val = np.array(data_gray['x_validation'])
y_val = np.array(data_gray['y_validation'])

# X = np.array(x_train) 
# Y = np.array(y_train)
# #filtered X and Y
# filx = []
# fily = [] 
# # print(X.shape,"shape")
# # print(len(X), "len")
# c = np.zeros(43)

# # # ls = [0,14,18,23,33]
# size = 1500

# for i in range(len(X)):
#   #get the corresponding class y = 0, 14, 18, 23, 33
#   jk = y_train[i]
#   if(c[jk]<size):
#     filx.append(X[i])
#     fily.append(Y[i])
#     c[jk]+=1
# print(np.array(filx).shape, "fil shape")
# print(x_test.shape)


# fil = np.array(filx).reshape(64500,1024)
# fily = np.array(fily)
# print(filx.shape)
# print(fily.shape)
# x_test = np.array(x_test).reshape(12630,1024)
# y_test = np.array(y_test)
# img = filx[0]
# plt.imshow(img[0])
# plt.show()

trn_sample = np.array(x_train).reshape(len(x_train),1024)
trn_label = np.array(y_train)
print(trn_sample.shape)
print(trn_label.shape)
ts_sample = np.array(x_test).reshape(len(x_test),1024)
ts_label = np.array(y_test)

vl_sample = np.array(x_val).reshape(len(x_val),1024)
vl_label = np.array(y_val)

train_x = np.array(x_train)
train_y = np.array(y_train)

# train_x, val_x, train_y, val_y = train_test_split(train_x,train_y,test_size=0.2)
(train_x.shape, train_y.shape)#, (val_x.shape, val_y.shape)

train_x = torch.from_numpy(train_x)
train_y = torch.from_numpy(train_y)
train_x.shape, train_y.shape
val_x = torch.from_numpy(x_val)
val_y = torch.from_numpy(y_val)
val_x.shape, val_y.shape

test_x = torch.from_numpy(x_test)
test_y = torch.from_numpy(y_test)


train_data = []
for i in range(len(train_x)):
  train_data.append([train_x[i],train_y[i]])

trainloader = torch.utils.data.DataLoader(train_data,shuffle=True,batch_size = 64)

test_data = []
for i in range(len(x_test)):
  test_data.append([x_test[i],y_test[i]])

testloader = torch.utils.data.DataLoader(test_data,shuffle=True,batch_size = 64)


val_data = []
for i in range(len(x_val)):
  val_data.append([x_val[i],y_val[i]])

valloader = torch.utils.data.DataLoader(val_data,shuffle=True,batch_size = 64)

print(len(trainloader.dataset))
print(len(testloader.dataset))
print(len(valloader.dataset))
# i1, l1 = next(iter(trainloader))
# print(i1.shape)
# i2,l2 = next(iter(trainloader))
# print(i2.shape)

dropout = 0.125
class CNN_Network(torch.nn.Module):

    def __init__(self):
        super(CNN_Network, self).__init__()

        self.layer1 = torch.nn.Sequential(
            torch.nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1),
            torch.nn.ReLU(),
            torch.nn.BatchNorm2d(16),
            torch.nn.MaxPool2d(kernel_size=2, stride=2),
            torch.nn.Dropout(p=dropout))
        # self.bn1 = torch.nn.BatchNorm2d(16)

        self.layer2 = torch.nn.Sequential(
            torch.nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),
            torch.nn.ReLU(),
            torch.nn.BatchNorm2d(32),
            torch.nn.MaxPool2d(kernel_size=2, stride=2),
            torch.nn.Dropout(p=dropout))
        # self.bn2 = torch.nn.BatchNorm2d(32)

        self.layer3 = torch.nn.Sequential(
            torch.nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),
            torch.nn.ReLU(),
            torch.nn.BatchNorm2d(64),
            torch.nn.MaxPool2d(kernel_size=2, stride=2),
            torch.nn.Dropout(p=dropout))
        # self.bn3 = torch.nn.BatchNorm2d(64)

        self.fc1 = torch.nn.Linear(4 * 4 * 64, 500, bias=True)
        torch.nn.init.xavier_uniform(self.fc1.weight)
        self.layer4 = torch.nn.Sequential(
            self.fc1,
            torch.nn.ReLU(),
            torch.nn.Dropout(p=dropout))
        
        # self.fc2 = torch.nn.Linear(256, 84, bias=True)
        # torch.nn.init.xavier_uniform(self.fc2.weight)
        # self.layer5 = torch.nn.Sequential(
        #     self.fc2,
        #     torch.nn.ReLU(),
        #     torch.nn.Dropout(p=dropout))

        self.fc2 = torch.nn.Linear(500, 43, bias=True)
        torch.nn.init.xavier_uniform_(self.fc2.weight) # initialize parameters

    def forward(self, x):
        out = self.layer1(x)
        out = self.layer2(out)
        out = self.layer3(out)
        out = out.view(out.size(0), -1)   # Flatten them for FC
        out = self.fc1(out)
        features = out
        out = self.fc2(out)
        # out = self.fc3(out)
        return out,features

#previously 16,32,64,500
# instantiate CNN model
model = CNN_Network()
# model

for param in model.parameters():
    print(param.size())

learning_rate = 0.0005
criterion = torch.nn.CrossEntropyLoss()  
optimizer = torch.optim.Adam(params=model.parameters(), lr=learning_rate)

if torch.cuda.is_available():
    model = model.cuda()
    criterion = criterion.cuda()

print(model)


# train_x = torch.from_numpy(train_x)
# # train_y = train_y.astype(int)
# train_y = torch.from_numpy(train_y)

epochs = 250
losses = []
losses_val = []
loss_epoch = []
loss_epoch_val = []
accr_train = []
accr_val = []

for epoch in range(epochs):
  loss_val = 0
  # print(len(trainloader.dataset))
  for i,(x,y) in enumerate(trainloader):
    x = Variable(x.float())
    y = Variable(y)
    # print(i)
    # print(x.shape)
    # print(y.shape)
    if torch.cuda.is_available():
      x = x.cuda()
      y = y.cuda()

    optimizer.zero_grad()
    output_train,_ = model(x)
    loss_train = criterion(output_train,y)
    loss_val+=loss_train.data
    loss_train.backward()
    optimizer.step()
    losses.append(loss_train.data)

  print('Epoch: %d, loss: %.4f' %(epoch,loss_val))
  loss_epoch.append(loss_val)
  with torch.no_grad():
      output,_ = model(train_x.cuda())   
  softmax = torch.exp(output).cpu()
  prob = list(softmax.numpy())
  predictions = np.argmax(prob, axis=1)

  print("accuracy for testing",end = ' ')
  accr_train.append(accuracy_score(np.array(train_y), predictions))
  print(accuracy_score(np.array(train_y), predictions))
  print("##############################################")
  loss_val2 = 0
  for i,(x,y) in enumerate(valloader):
    x = Variable(x.float())
    y = Variable(y.long())
    # print(i)
    # print(x.shape)
    # print(y.shape)
    if torch.cuda.is_available():
      x = x.cuda()
      y = y.cuda()

    # optimizer.zero_grad()
    output_val,_ = model(x)
    loss_valid = criterion(output_val,y)
    loss_val2+=loss_valid.data
    # loss_valid.backward()
    # optimizer.step()
    losses_val.append(loss_valid.data)

  print('Epoch: %d, loss: %.4f' %(epoch,loss_val2))
  loss_epoch_val.append(loss_val2)
  with torch.no_grad():
      output,_ = model(val_x.cuda())   
  softmax = torch.exp(output).cpu()
  prob = list(softmax.numpy())
  predictions = np.argmax(prob, axis=1)

  print("accuracy for validation",end = ' ')
  accr_val.append(accuracy_score(np.array(val_y), predictions))
  print(accuracy_score(np.array(val_y), predictions))
  print("##############################################")

model = unpickle('/content/drive/My Drive/ML/CNN_model_250')

filename = "CNN_model"
pickle.dump(model,open(filename,'wb'))

# print(loss_epoch)
loss_per_epoch = []
# print(loss_epoch[0])
for i in range(len(loss_epoch)):
  loss_per_epoch.append(float(loss_epoch[i]))
# print(len(loss_per_epoch))
plt.plot(loss_per_epoch)
plt.ylabel("loss_per_epoch")
plt.xlabel("epoch")
plt.title("loss_train vs epoch")
plt.show()

loss_per_epoch_val = []
# print(loss_epoch[0])
for i in range(len(loss_epoch_val)):
  loss_per_epoch_val.append(float(loss_epoch_val[i]))
# print(len(loss_per_epoch_val))
plt.plot(loss_per_epoch_val)
plt.ylabel("loss_per_epoch_val")
plt.xlabel("epoch")
plt.title("loss_val vs epoch")
plt.show()

plt.plot(accr_train)
plt.ylabel("accuracy per epoch training")
plt.xlabel("epoch")
plt.show()

plt.plot(accr_val)
plt.ylabel("accuracy per epoch validationo")
plt.xlabel("epoch")
plt.show()

with torch.no_grad():
    output,_ = model(train_x.cuda())
    
softmax = torch.exp(output).cpu()
prob = list(softmax.numpy())
# prob = np.array(prob,axis=1)
# print(softmax)
# print("prob_______________________________________00")
# print(prob.shape)
predictions1 = np.argmax(prob, axis=1)
print(predictions1)
# for i in range(len(prob)):
#   print(predictions[i],end=" ")
#   print(train_y[i])
#   print()

print("-------------------------------")
print((train_y))

# accuracy on training set
print(accuracy_score(np.array(train_y), predictions1))


print("for training dataset")
print("##############################################")
with torch.no_grad():
    output,_ = model(val_x.cuda())   
softmax = torch.exp(output).cpu()
prob = list(softmax.numpy())
predictions2 = np.argmax(prob, axis=1)
print(predictions2)
# for i in range(len(prob)):
#   print(predictions[i],end=" ")
#   print(train_y[i])
#   print()

print("-------------------------------")
print((val_y))

# accuracy on training set
print(accuracy_score(np.array(val_y), predictions2))
print("for validation dataset  ")
print("##############################################")
with torch.no_grad():
    output,_ = model(test_x.cuda())   
softmax = torch.exp(output).cpu()
prob = list(softmax.numpy())
predictions = np.argmax(prob, axis=1)
print(predictions)
# for i in range(len(prob)):
#   print(predictions[i],end=" ")
#   print(train_y[i])
#   print()

print("-------------------------------")
print((test_y))

# accuracy on training set
print(accuracy_score(np.array(test_y), predictions))
print("for testing dataset  ")

# # #ROC and various confusion metrics for CNN
# fpr = dict()
# tpr = dict()
# roc_auc = dict()
# y_score = model.decision_function(x_test)
# y_tester = np.zeros(np.array(test_y).size)
# for i in range(43):
#   for j in range(len(test_y)):
#     if(test_y[j]==i):
#       y_tester[j] = 1
#     else:
#       y_tester[j] = 0
#   fpr[i],tpr[i],thresh = roc_curve(test_y,y_score[:,i])
#   roc_auc[i] = auc(fpr[i],tpr[i])
# for i in range(43):
#   plt.plot(fpr[i],tpr[i],label = ("ROC_class :"+str(i)))
# plt.plot([0,1],[0,1],'k--')
# plt.ylabel('True positive rate')
# plt.xlabel('False positive rate')
# plt.title('ROC curve for CNN model')
# plt.show()

# predict probabilities for test set


# accuracy: (tp + tn) / (p + n)
print("for CNN model")
accuracy = accuracy_score(y_train, predictions1)
print("Accuracy on Train: ",end = '')
print(accuracy)

accuracy = accuracy_score(y_val, predictions2)
print("Accuracy on val: ",end = '')
print(accuracy)

accuracy = accuracy_score(y_test, predictions)
print("Accuracy on Test: ",end = '')
print(accuracy)

precision = precision_score(y_test, predictions,  average='macro')
print("Precision: ",end = '')
print(precision)

recall = recall_score(y_test,predictions,average = 'macro')
print("recall_score: ",end = '')
print(recall)

from sklearn.metrics import confusion_matrix
matrix = confusion_matrix(y_test, predictions)

import matplotlib.pyplot as plt
import seaborn as sns

sns.heatmap(matrix,annot=False,cbar=True)
# sns

train_sample = np.zeros((1,500))
train_label = np.array([])

for images,labels in trainloader:
  images = Variable(images.float())
  labels = Variable(labels)
  if torch.cuda.is_available():
      images = images.cuda()
  tes = np.array(labels.tolist())

  _,features = model(images)
  features = np.array(features.tolist())
  train_sample = np.vstack([train_sample,features])
  train_label = np.append(train_label,tes)

train_sample = np.array(train_sample[1:])
print(train_sample.shape)
print(train_label.shape)

val_sample = np.zeros((1,500))
val_label = np.array([])

for images,labels in valloader:
  images = Variable(images.float())
  labels = Variable(labels)
  if torch.cuda.is_available():
      images = images.cuda()
  tes = np.array(labels.tolist())

  _,features = model(images)
  features = np.array(features.tolist())
  val_sample = np.vstack([val_sample,features])
  val_label = np.append(val_label,tes)

val_sample = np.array(val_sample[1:])
print(val_sample.shape)
print(val_label.shape)

test_sample = np.zeros((1,500))
test_label = np.array([])

for images,labels in testloader:
  images = Variable(images.float())
  labels = Variable(labels)
  if torch.cuda.is_available():
      images = images.cuda()
  tes = np.array(labels.tolist())

  _,features = model(images)
  features = np.array(features.tolist())
  test_sample = np.vstack([test_sample,features])
  test_label = np.append(test_label,tes)

test_sample = np.array(test_sample[1:])
print(test_sample.shape)
print(test_label.shape)

#Implementing Logistic With Extracted Features from CNN
from sklearn.linear_model import LogisticRegression
from sklearn import metrics

logistic_model = LogisticRegression(solver='lbfgs')
logistic_model.fit(train_sample,train_label)
y_pred_logistic = logistic_model.predict(test_sample)

logistic_model = unpickle('/content/drive/My Drive/ML/Logistic_model')

print("for Logistic model")
# y_pred_logistic = logistic_model.predict(test_sample)

train_logis_pred = logistic_model.predict(train_sample)
accuracy = accuracy_score(train_label, train_logis_pred)
print("Accuracy on Train: ",end = '')
print(accuracy)

val_logis_pred = logistic_model.predict(val_sample)
accuracy = accuracy_score(val_label, val_logis_pred)
print("Accuracy on val: ",end = '')
print(accuracy)

test_logis_pred = logistic_model.predict(test_sample)
accuracy = accuracy_score(test_label, test_logis_pred)
print("Accuracy on test: ",end = '')
print(accuracy)

precision = precision_score(test_label, test_logis_pred,  average='macro')
print("Precision: ",end = '')
print(precision)

recall = recall_score(test_label, test_logis_pred,average = 'macro')
print("recall_score: ",end = '')
print(recall)
print()

#ROC and various confusion metrics for CNN
fpr = dict()
tpr = dict()
roc_auc = dict()
y_score = logistic_model.decision_function(test_sample)
y_tester = np.zeros(np.array(test_label).size)
for i in range(43):
  for j in range(len(test_label)):
    if(test_label[j]==i):
      y_tester[j] = 1
    else:
      y_tester[j] = 0
  fpr[i],tpr[i],thresh = roc_curve(y_tester,y_score[:,i])
  roc_auc[i] = auc(fpr[i],tpr[i])
for i in range(43):
  plt.plot(fpr[i],tpr[i],label = ("ROC_class :"+str(i)))
plt.plot([0,1],[0,1],'k--')
plt.ylabel('True positive rate')
plt.xlabel('False positive rate')
plt.title('ROC curve for Logistic with CNN')
plt.show()

from sklearn.metrics import confusion_matrix
matrix = confusion_matrix(test_label,test_logis_pred )

import matplotlib.pyplot as plt
import seaborn as sns

sns.heatmap(matrix,annot=False,cbar=True)

filename_logistic = "Logistic_model"
pickle.dump(logistic_model,open(filename_logistic,'wb'))

from sklearn import svm
from sklearn.metrics import confusion_matrix,accuracy_score
svm_rbf_model = svm.SVC(kernel = 'rbf',gamma = 'scale', decision_function_shape = 'ovr')
svm_rbf_model.fit(train_sample,train_label)

svm_rbf_model = unpickle('/content/drive/My Drive/ML/svm_rbf_model')

# print("for SVM RBF model")
# train_rbf_pred = svm_rbf_model.predict(train_sample)
# accuracy = accuracy_score(train_label, train_rbf_pred)
# print("Accuracy on Train: ",end = '')
# print(accuracy)

# val_rbf_pred = svm_rbf_model.predict(val_sample)
# accuracy = accuracy_score(val_label, val_rbf_pred)
# print("Accuracy on val: ",end = '')
# print(accuracy)

test_rbf_pred = svm_rbf_model.predict(test_sample)
accuracy = accuracy_score(test_label, test_rbf_pred)
print("Accuracy on test: ",end = '')
print(accuracy)

precision = precision_score(test_label, test_rbf_pred,  average='macro')
print("Precision: ",end = '')
print(precision)

recall = recall_score(test_label, test_rbf_pred,average = 'macro')
print("recall_score: ",end = '')
print(recall)
print()

#ROC and various confusion metrics for CNN
fpr = dict()
tpr = dict()
roc_auc = dict()
y_score = svm_rbf_model.decision_function(test_sample)
y_tester = np.zeros(np.array(test_label).size)
for i in range(43):
  for j in range(len(test_label)):
    if(test_label[j]==i):
      y_tester[j] = 1
    else:
      y_tester[j] = 0
  fpr[i],tpr[i],thresh = roc_curve(y_tester,y_score[:,i])
  roc_auc[i] = auc(fpr[i],tpr[i])
for i in range(43):
  plt.plot(fpr[i],tpr[i],label = ("ROC_class :"+str(i)))
plt.plot([0,1],[0,1],'k--')
plt.ylabel('True positive rate')
plt.xlabel('False positive rate')
plt.title('ROC curve for RBF with CNN feature')
plt.show()

from sklearn.metrics import confusion_matrix
matrix = confusion_matrix(test_label,test_rbf_pred )

import matplotlib.pyplot as plt
import seaborn as sns

sns.heatmap(matrix,annot=False,cbar=True)

filename_svm_rbf = "svm_rbf_model"
pickle.dump(svm_rbf_model,open(filename_svm_rbf,'wb'))

from sklearn import svm
from sklearn.metrics import confusion_matrix,accuracy_score
svm_poly_model = svm.SVC(kernel = 'poly',degree = 3, decision_function_shape = 'ovr')
svm_poly_model.fit(train_sample,train_label)

svm_poly_model = unpickle('/content/drive/My Drive/ML/svm_poly_model')

print("for SVM POLY model")
# train_poly_pred = svm_poly_model.predict(train_sample)
# accuracy = accuracy_score(train_label, train_poly_pred)
# print("Accuracy on Train: ",end = '')
# print(accuracy)

# val_poly_pred = svm_poly_model.predict(val_sample)
# accuracy = accuracy_score(val_label, val_poly_pred)
# print("Accuracy on val: ",end = '')
# print(accuracy)

test_poly_pred = svm_poly_model.predict(test_sample)
accuracy = accuracy_score(test_label, test_poly_pred)
print("Accuracy on test: ",end = '')
print(accuracy)

precision = precision_score(test_label, test_poly_pred,  average='macro')
print("Precision: ",end = '')
print(precision)

recall = recall_score(test_label, test_poly_pred,average = 'macro')
print("recall_score: ",end = '')
print(recall)
print()

#ROC and various confusion metrics for CNN
fpr = dict()
tpr = dict()
roc_auc = dict()
y_score = svm_poly_model.decision_function(test_sample)
y_tester = np.zeros(np.array(test_label).size)
for i in range(43):
  for j in range(len(test_label)):
    if(test_label[j]==i):
      y_tester[j] = 1
    else:
      y_tester[j] = 0
  fpr[i],tpr[i],thresh = roc_curve(y_tester,y_score[:,i])
  roc_auc[i] = auc(fpr[i],tpr[i])
for i in range(43):
  plt.plot(fpr[i],tpr[i],label = ("ROC_class :"+str(i)))
plt.plot([0,1],[0,1],'k--')
plt.ylabel('True positive rate')
plt.xlabel('False positive rate')
plt.title('ROC curve for POLY with CNN feature')
plt.show()
from sklearn.metrics import confusion_matrix
matrix = confusion_matrix(test_label,test_poly_pred )

import matplotlib.pyplot as plt
import seaborn as sns

sns.heatmap(matrix,annot=False,cbar=True)

filename_poly_rbf = "svm_poly_model"
pickle.dump(svm_poly_model,open(filename_poly_rbf,'wb'))

from sklearn import svm
from sklearn.metrics import confusion_matrix,accuracy_score
svm_linear_model = svm.SVC(kernel = 'linear',decision_function_shape = 'ovr')
svm_linear_model.fit(train_sample,train_label)

svm_linear_model = unpickle('/content/drive/My Drive/ML/svm_linear_model')

print("for SVM LINEAR model")
# train_linear_pred = svm_linear_model.predict(train_sample)
# accuracy = accuracy_score(train_label, train_linear_pred)
# print("Accuracy on Train: ",end = '')
# print(accuracy)

# val_linear_pred = svm_linear_model.predict(val_sample)
# accuracy = accuracy_score(val_label, val_linear_pred)
# print("Accuracy on val: ",end = '')
# print(accuracy)

test_linear_pred = svm_linear_model.predict(test_sample)
accuracy = accuracy_score(test_label, test_linear_pred)
print("Accuracy on test: ",end = '')
print(accuracy)

precision = precision_score(test_label, test_linear_pred,  average='macro')
print("Precision: ",end = '')
print(precision)

recall = recall_score(test_label, test_linear_pred,average = 'macro')
print("recall_score: ",end = '')
print(recall)
print()

#ROC and various confusion metrics for CNN
fpr = dict()
tpr = dict()
roc_auc = dict()
y_score = svm_linear_model.decision_function(test_sample)
y_tester = np.zeros(np.array(test_label).size)
for i in range(43):
  for j in range(len(test_label)):
    if(test_label[j]==i):
      y_tester[j] = 1
    else:
      y_tester[j] = 0
  fpr[i],tpr[i],thresh = roc_curve(y_tester,y_score[:,i])
  roc_auc[i] = auc(fpr[i],tpr[i])
for i in range(43):
  plt.plot(fpr[i],tpr[i],label = ("ROC_class :"+str(i)))
plt.plot([0,1],[0,1],'k--')
plt.ylabel('True positive rate')
plt.xlabel('False positive rate')
plt.title('ROC curve for LINEAR with CNN feature')
plt.show()
from sklearn.metrics import confusion_matrix
matrix = confusion_matrix(test_label,test_linear_pred )

import matplotlib.pyplot as plt
import seaborn as sns

sns.heatmap(matrix,annot=False,cbar=True)

filename_linear_rbf = "svm_linear_model"
pickle.dump(svm_linear_model,open(filename_linear_rbf,'wb'))

model_relu = MLPClassifier(hidden_layer_sizes=(256,128,64),activation='relu',batch_size = 64,max_iter=300,learning_rate_init=0.00145,verbose = True)
model_relu.fit(train_sample,train_label)

model_relu = unpickle('/content/drive/My Drive/ML/model_relu')

print("for MLP model")
# train_MLP_pred = model_relu.predict(train_sample)
# accuracy = accuracy_score(train_label, train_MLP_pred)
# print("Accuracy on Train: ",end = '')
# print(accuracy)

# val_MLP_pred = model_relu.predict(val_sample)
# accuracy = accuracy_score(val_label, val_MLP_pred)
# print("Accuracy on val: ",end = '')
# print(accuracy)

test_MLP_pred = model_relu.predict(test_sample)
accuracy = accuracy_score(test_label, test_MLP_pred)
print("Accuracy on test: ",end = '')
print(accuracy)

precision = precision_score(test_label, test_MLP_pred,  average='macro')
print("Precision: ",end = '')
print(precision)

recall = recall_score(test_label, test_MLP_pred,average = 'macro')
print("recall_score: ",end = '')
print(recall)
print()

from sklearn.metrics import confusion_matrix
matrix = confusion_matrix(test_label,test_MLP_pred )

import matplotlib.pyplot as plt
import seaborn as sns

sns.heatmap(matrix,annot=False,cbar=True)

# #ROC and various confusion metrics for CNN
# fpr = dict()
# tpr = dict()
# roc_auc = dict()
# y_score = model_relu.decision_function(test_sample)
# y_tester = np.zeros(np.array(test_label).size)
# for i in range(43):
#   for j in range(len(test_label)):
#     if(test_label[j]==i):
#       y_tester[j] = 1
#     else:
#       y_tester[j] = 0
#   fpr[i],tpr[i],thresh = roc_curve(y_tester,y_score[:,i])
#   roc_auc[i] = auc(fpr[i],tpr[i])
# for i in range(43):
#   plt.plot(fpr[i],tpr[i],label = ("ROC_class :"+str(i)))
# plt.plot([0,1],[0,1],'k--')
# plt.ylabel('True positive rate')
# plt.xlabel('False positive rate')
# plt.title('ROC curve for MLP with RELU with CNN feature')
# plt.show()

filename_MLP_relu = "model_relu"
pickle.dump(model_relu,open(filename_MLP_relu,'wb'))

from sklearn.ensemble import RandomForestClassifier

random_fr_model = RandomForestClassifier(n_estimators=100, max_depth=50,max_features = 'sqrt')
random_fr_model.fit(train_sample,train_label)

print("for RFR model")
train_rfr_pred = random_fr_model.predict(train_sample)
accuracy = accuracy_score(train_label, train_rfr_pred)
print("Accuracy on Train: ",end = '')
print(accuracy)

val_rfr_pred = random_fr_model.predict(val_sample)
accuracy = accuracy_score(val_label, val_rfr_pred)
print("Accuracy on val: ",end = '')
print(accuracy)

test_rfr_pred = random_fr_model.predict(test_sample)
accuracy = accuracy_score(test_label, test_rfr_pred)
print("Accuracy on test: ",end = '')
print(accuracy)

precision = precision_score(test_label, test_rfr_pred,  average='macro')
print("Precision: ",end = '')
print(precision)

recall = recall_score(test_label, test_rfr_pred,average = 'macro')
print("recall_score: ",end = '')
print(recall)
print()

#ROC and various confusion metrics for CNN
# fpr = dict()
# tpr = dict()
# roc_auc = dict()
# y_score = random_fr_model.decision_function(test_sample)
# y_tester = np.zeros(np.array(test_label).size)
# for i in range(43):
#   for j in range(len(test_label)):
#     if(test_label[j]==i):
#       y_tester[j] = 1
#     else:
#       y_tester[j] = 0
#   fpr[i],tpr[i],thresh = roc_curve(y_tester,y_score[:,i])
#   roc_auc[i] = auc(fpr[i],tpr[i])
# for i in range(43):
#   plt.plot(fpr[i],tpr[i],label = ("ROC_class :"+str(i)))
# plt.plot([0,1],[0,1],'k--')
# plt.ylabel('True positive rate')
# plt.xlabel('False positive rate')
# plt.title('ROC curve for Random fr with CNN feature')
# plt.show()

from sklearn.metrics import confusion_matrix
matrix = confusion_matrix(test_label,test_rfr_pred )

import matplotlib.pyplot as plt
import seaborn as sns

sns.heatmap(matrix,annot=False,cbar=True)

filename_random_fr = 'Random_forest_Classifier'
pickle.dump(random_fr_model,open(filename_random_fr,'wb'))

model_relu = MLPClassifier(hidden_layer_sizes=(256,128,64),activation='relu',batch_size = 128,max_iter=75,learning_rate_init=0.0001,verbose = True)
model_relu.fit(trn_sample,trn_label)

print("for MLP model with raw data")
train_MLP_pred = model_relu.predict(trn_sample)
accuracy = accuracy_score(trn_label, train_MLP_pred)
print("Accuracy on Train: ",end = '')
print(accuracy)

val_MLP_pred = model_relu.predict(vl_sample)
accuracy = accuracy_score(vl_label, val_MLP_pred)
print("Accuracy on val: ",end = '')
print(accuracy)

test_MLP_pred = model_relu.predict(ts_sample)
accuracy = accuracy_score(ts_label, test_MLP_pred)
print("Accuracy on test: ",end = '')
print(accuracy)

precision = precision_score(ts_label, test_MLP_pred,  average='macro')
print("Precision: ",end = '')
print(precision)

recall = recall_score(ts_label, test_MLP_pred,average = 'macro')
print("recall_score: ",end = '')
print(recall)
print()

from sklearn.metrics import confusion_matrix
matrix = confusion_matrix(ts_label,test_MLP_pred )

import matplotlib.pyplot as plt
import seaborn as sns

sns.heatmap(matrix,annot=False,cbar=True)

# #ROC and various confusion metrics for CNN
# fpr = dict()
# tpr = dict()
# roc_auc = dict()
# y_score = model_relu.decision_function(test_sample)
# y_tester = np.zeros(np.array(test_label).size)
# for i in range(43):
#   for j in range(len(test_label)):
#     if(test_label[j]==i):
#       y_tester[j] = 1
#     else:
#       y_tester[j] = 0
#   fpr[i],tpr[i],thresh = roc_curve(y_tester,y_score[:,i])
#   roc_auc[i] = auc(fpr[i],tpr[i])
# for i in range(43):
#   plt.plot(fpr[i],tpr[i],label = ("ROC_class :"+str(i)))
# plt.plot([0,1],[0,1],'k--')
# plt.ylabel('True positive rate')
# plt.xlabel('False positive rate')
# plt.title('ROC curve for MLP with RELU with CNN feature')
# plt.show()

#Implementing Logistic With Extracted Features from CNN
from sklearn.linear_model import LogisticRegression
from sklearn import metrics

logistic_model = LogisticRegression(solver='lbfgs')
logistic_model.fit(trn_sample,trn_label)

print("for Logistic model")
# y_pred_logistic = logistic_model.predict(test_sample)

train_logis_pred = logistic_model.predict(trn_sample)
accuracy = accuracy_score(trn_label, train_logis_pred)
print("Accuracy on Train: ",end = '')
print(accuracy)

val_logis_pred = logistic_model.predict(vl_sample)
accuracy = accuracy_score(vl_label, val_logis_pred)
print("Accuracy on val: ",end = '')
print(accuracy)

test_logis_pred = logistic_model.predict(ts_sample)
accuracy = accuracy_score(ts_label, test_logis_pred)
print("Accuracy on test: ",end = '')
print(accuracy)

precision = precision_score(ts_label, test_logis_pred,  average='macro')
print("Precision: ",end = '')
print(precision)

recall = recall_score(ts_label, test_logis_pred,average = 'macro')
print("recall_score: ",end = '')
print(recall)
print()

#ROC and various confusion metrics for CNN
fpr = dict()
tpr = dict()
roc_auc = dict()
y_score = logistic_model.decision_function(ts_sample)
y_tester = np.zeros(np.array(ts_label).size)
for i in range(43):
  for j in range(len(ts_label)):
    if(ts_label[j]==i):
      y_tester[j] = 1
    else:
      y_tester[j] = 0
  fpr[i],tpr[i],thresh = roc_curve(y_tester,y_score[:,i])
  roc_auc[i] = auc(fpr[i],tpr[i])
for i in range(43):
  plt.plot(fpr[i],tpr[i],label = ("ROC_class :"+str(i)))
plt.plot([0,1],[0,1],'k--')
plt.ylabel('True positive rate')
plt.xlabel('False positive rate')
plt.title('ROC curve for Logistic with RAW data')
plt.show()

from sklearn.metrics import confusion_matrix
matrix = confusion_matrix(ts_label,test_logis_pred )

import matplotlib.pyplot as plt
import seaborn as sns

sns.heatmap(matrix,annot=False,cbar=True)

from sklearn import svm
from sklearn.metrics import confusion_matrix,accuracy_score
svm_linear_model = svm.SVC(kernel = 'linear',decision_function_shape = 'ovr')
svm_linear_model.fit(trn_sample,trn_label)

train_linear_pred = svm_linear_model.predict(trn_sample)
accuracy = accuracy_score(trn_label, train_linear_pred)
print("Accuracy on Train: ",end = '')
print(accuracy)

val_linear_pred = svm_linear_model.predict(vl_sample)
accuracy = accuracy_score(vl_label, val_linear_pred)
print("Accuracy on val: ",end = '')
print(accuracy)

test_linear_pred = svm_linear_model.predict(ts_sample)
accuracy = accuracy_score(ts_label, test_linear_pred)
print("Accuracy on test: ",end = '')
print(accuracy)

precision = precision_score(ts_label, test_linear_pred,  average='macro')
print("Precision: ",end = '')
print(precision)

recall = recall_score(ts_label, test_linear_pred,average = 'macro')
print("recall_score: ",end = '')
print(recall)
print()

#ROC and various confusion metrics for CNN
fpr = dict()
tpr = dict()
roc_auc = dict()
y_score = svm_linear_model.decision_function(ts_sample)
y_tester = np.zeros(np.array(ts_label).size)
for i in range(43):
  for j in range(len(ts_label)):
    if(ts_label[j]==i):
      y_tester[j] = 1
    else:
      y_tester[j] = 0
  fpr[i],tpr[i],thresh = roc_curve(y_tester,y_score[:,i])
  roc_auc[i] = auc(fpr[i],tpr[i])
for i in range(43):
  plt.plot(fpr[i],tpr[i],label = ("ROC_class :"+str(i)))
plt.plot([0,1],[0,1],'k--')
plt.ylabel('True positive rate')
plt.xlabel('False positive rate')
plt.title('ROC curve for Svm Linear with RAW data')
plt.show()

from sklearn.metrics import confusion_matrix
matrix = confusion_matrix(ts_label,test_linear_pred )

import matplotlib.pyplot as plt
import seaborn as sns

sns.heatmap(matrix,annot=False,cbar=True)

from sklearn import svm
from sklearn.metrics import confusion_matrix,accuracy_score
svm_poly_model = svm.SVC(kernel = 'poly',degree = 3,decision_function_shape = 'ovr')
svm_poly_model.fit(trn_sample,trn_label)

train_poly_pred = svm_poly_model.predict(trn_sample)
accuracy = accuracy_score(trn_label, train_poly_pred)
print("Accuracy on Train: ",end = '')
print(accuracy)

val_poly_pred = svm_poly_model.predict(vl_sample)
accuracy = accuracy_score(vl_label, val_poly_pred)
print("Accuracy on val: ",end = '')
print(accuracy)

test_poly_pred = svm_poly_model.predict(ts_sample)
accuracy = accuracy_score(ts_label, test_poly_pred)
print("Accuracy on test: ",end = '')
print(accuracy)

precision = precision_score(ts_label, test_poly_pred,  average='macro')
print("Precision: ",end = '')
print(precision)

recall = recall_score(ts_label, test_poly_pred,average = 'macro')
print("recall_score: ",end = '')
print(recall)
print()

#ROC and various confusion metrics for CNN
fpr = dict()
tpr = dict()
roc_auc = dict()
y_score = svm_poly_model.decision_function(ts_sample)
y_tester = np.zeros(np.array(ts_label).size)
for i in range(43):
  for j in range(len(ts_label)):
    if(ts_label[j]==i):
      y_tester[j] = 1
    else:
      y_tester[j] = 0
  fpr[i],tpr[i],thresh = roc_curve(y_tester,y_score[:,i])
  roc_auc[i] = auc(fpr[i],tpr[i])
for i in range(43):
  plt.plot(fpr[i],tpr[i],label = ("ROC_class :"+str(i)))
plt.plot([0,1],[0,1],'k--')
plt.ylabel('True positive rate')
plt.xlabel('False positive rate')
plt.title('ROC curve for SVM POLY with RAW data')
plt.show()

from sklearn.metrics import confusion_matrix
matrix = confusion_matrix(ts_label,test_poly_pred )

import matplotlib.pyplot as plt
import seaborn as sns

sns.heatmap(matrix,annot=False,cbar=True)

from sklearn import svm
from sklearn.metrics import confusion_matrix,accuracy_score
svm_rbf_model = svm.SVC(kernel = 'rbf',gamma = 'scale', decision_function_shape = 'ovr')
svm_rbf_model.fit(trn_sample,trn_label)

train_rbf_pred = svm_rbf_model.predict(trn_sample)
accuracy = accuracy_score(trn_label, train_rbf_pred)
print("Accuracy on Train: ",end = '')
print(accuracy)

val_rbf_pred = svm_rbf_model.predict(vl_sample)
accuracy = accuracy_score(vl_label, val_rbf_pred)
print("Accuracy on val: ",end = '')
print(accuracy)

test_rbf_pred = svm_rbf_model.predict(ts_sample)
accuracy = accuracy_score(ts_label, test_rbf_pred)
print("Accuracy on test: ",end = '')
print(accuracy)

precision = precision_score(ts_label, test_rbf_pred,  average='macro')
print("Precision: ",end = '')
print(precision)

recall = recall_score(ts_label, test_rbf_pred,average = 'macro')
print("recall_score: ",end = '')
print(recall)
print()

#ROC and various confusion metrics for CNN
fpr = dict()
tpr = dict()
roc_auc = dict()
y_score = svm_rbf_model.decision_function(ts_sample)
y_tester = np.zeros(np.array(ts_label).size)
for i in range(43):
  for j in range(len(ts_label)):
    if(ts_label[j]==i):
      y_tester[j] = 1
    else:
      y_tester[j] = 0
  fpr[i],tpr[i],thresh = roc_curve(y_tester,y_score[:,i])
  roc_auc[i] = auc(fpr[i],tpr[i])
for i in range(43):
  plt.plot(fpr[i],tpr[i],label = ("ROC_class :"+str(i)))
plt.plot([0,1],[0,1],'k--')
plt.ylabel('True positive rate')
plt.xlabel('False positive rate')
plt.title('ROC curve for SVM RBF with RAW data')
plt.show()

from sklearn.metrics import confusion_matrix
matrix = confusion_matrix(ts_label,test_rbf_pred )

import matplotlib.pyplot as plt
import seaborn as sns

sns.heatmap(matrix,annot=False,cbar=True)

from sklearn.neighbors import KNeighborsClassifier
from sklearn import metrics

k_range = range(1,26)
scores = {}
scores_list = []
for k in k_range:
  knn = KNeighborsClassifier(n_neighbors=k)
  knn.fit(trn_sample,trn_label)
  pred = knn.predict(ts_sample)
  scores[k] = metrics.accuracy_score(ts_label,pred)
  scores_list.append(metrics.accuracy_score(ts_label,pred))
  print("testing accuracy")
  print(k)
  print(metrics.accuracy_score(ts_label,pred))

