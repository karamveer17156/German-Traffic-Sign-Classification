# -*- coding: utf-8 -*-
"""MainProject.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qLiz3-ENUx8Jx0PxeSDHYqwUA5xwOL1O
"""

from google.colab import drive

drive.mount('/content/drive')

print("HOPE")
import warnings
warnings.filterwarnings("ignore")
#to supress warnings

#make a function to unpickle
def unpickle(file):
    import pickle
    with open(file, 'rb') as fo:
        dict = pickle.load(fo, encoding='bytes')
    return dict
data_gray = unpickle('/content/drive/My Drive/ML/data5.pickle')



# #After data, Take only 5 classes and having 200 samples of each classes
# import numpy as np
# import torch
# print(data_gray.keys())
# x_train = data_gray['x_train']
# y_train = data_gray['y_train']
# #Now seperate out classes and downsample it :)
# c = [0,0,0,0,0]
# #Combine the result of Xtrain and Xval
# X = x_train 
# Y = y_train 
# X = np.array(X)
# Y = np.array(Y)
# filx = []
# fily = [] #filtered X and Y
# print(X.shape,"shape")
# print(len(X), "len")
# # k = []
# # ls = [0,14,18,23,33

# for i in range(len(X)):
#   #get the corresponding class y = 0, 14, 18, 23, 33
#   if(y_train[i]==0 and c[0]<200):
#     c[0]+=1
#     filx.append(X[i])
#     fily.append(Y[i])
#   if(y_train[i]==14 and c[1]<200):
#     filx.append(X[i])
#     fily.append(Y[i])
#     c[1]+=1
#   if(y_train[i]==18 and c[2]<200):
#     filx.append(X[i])
#     fily.append(Y[i])
#     c[2]+=1
#   if(y_train[i]==23 and c[3]<200):
#     filx.append(X[i])
#     fily.append(Y[i])
#     c[3]+=1
#   if(y_train[i]==33 and c[4]<200):
#     filx.append(X[i])
#     fily.append(Y[i])
#     c[4]+=1
# print(np.array(filx).shape, "fil shape")
# print(fily)

#After data, Take only 5 classes and having 200 samples of each classes
import numpy as np
print(data_gray.keys())
x_train = data_gray['x_train']
y_train = data_gray['y_train']
#Now seperate out classes and downsample it :)
c = [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
#Combine the result of Xtrain and Xval
X = x_train 
Y = y_train 
X = np.array(X)
Y = np.array(Y)
X_test = np.array(data_gray['x_test'])
Y_test = np.array(data_gray['y_test'])
filx = []
fily = [] #filtered X and Y
print(X.shape,"shape")
print(len(X), "len")
# k = []

# from skimage import data, io, filters
# ex_train = []
# ex_test = []
# for i in range(len(X)):
#   edges = filters.sobel(X[i][0])
#   ex_train.append(edges)
  
# #for testing data 
# for i in range(len(X_test)):
#   edges = filters.sobel(X_test[i][0])
#   ex_test.append(edges)
# ex_train=np.array(ex_train)
# ex_test=np.array(ex_test)
# print(ex_train.shape)
# print(ex_test.shape)


ls = [0,14,18,23,33]
size = 2500

for i in range(len(X)):
  #get the corresponding class y = 0, 14, 18, 23, 33
  jk = y_train[i]
  if(c[jk]<size):
    filx.append(X[i])
    fily.append(Y[i])
    c[jk]+=1
print(np.array(filx).shape, "fil shape")
print(fily)

#Scrapping features using HOG
from skimage.io import imread, imshow
from skimage.transform import resize
from skimage.feature import hog
from skimage import exposure
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import cv2
#reading the image
from PIL import Image
img = filx[1000]
htrain = []
htest = []
for i in range(len(filx)):
  img = X[i]
  img = img.reshape(32,32)
  fd, hog_image = hog(img, orientations=9, pixels_per_cell=(8, 8), cells_per_block=(2, 2), visualize=True, multichannel=False)
  fd = fd.reshape(len(fd),1)
  htrain.append(fd)
#Do the same with test 

htest = []
for i in range(len(X_test)):
  img = X_test[i]
  img = img.reshape(32,32)
  fd, hog_image = hog(img, orientations=9, pixels_per_cell=(8, 8), cells_per_block=(2, 2), visualize=True, multichannel=False)
  fd = fd.reshape(len(fd),1)
  htest.append(fd)
#got the Features from the image... now implement the same on SVM, logistic...

# print(htrain.shape)
# print(htest.shape)

hog_train = np.array(htrain).reshape(len(htrain),324)
hog_test = np.array(htest).reshape(len(htest),324)
print(hog_train.shape)
print(hog_test.shape)
hog_test_label = np.array(Y_test)
hog_train_label = np.array(fily)
print(hog_train_label.shape)
print(hog_test_label.shape)

import numpy as np
import torch
# from torch.nn import ReLU, Conv2d, Linear, Sequential, MaxPool2d, Module, Dropout 
from torch.autograd import Variable
import torchvision.datasets as dsets
import torchvision.transforms as transforms
import torch.nn.init
import matplotlib.pyplot as plt
# from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout
from torch.optim import Adam, SGD
from sklearn.model_selection import train_test_split
from sklearn.neural_network import MLPClassifier
import pickle
from sklearn.metrics import accuracy_score
from sklearn.metrics import f1_score
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
from sklearn.metrics import roc_curve,auc

model_relu = MLPClassifier(hidden_layer_sizes=(256,128,64),activation='relu',batch_size = 128,max_iter=75,learning_rate_init=0.0001,verbose = True)
model_relu.fit(hog_train,hog_train_label)

print("for MLP model with raw data")
train_MLP_pred = model_relu.predict(hog_train)
accuracy = accuracy_score(hog_train_label, train_MLP_pred)
print("Accuracy on Train: ",end = '')
print(accuracy)

# val_MLP_pred = model_relu.predict(vl_sample)
# accuracy = accuracy_score(vl_label, val_MLP_pred)
# print("Accuracy on val: ",end = '')
# print(accuracy)

test_MLP_pred = model_relu.predict(hog_test)
accuracy = accuracy_score(hog_test_label, test_MLP_pred)
print("Accuracy on test: ",end = '')
print(accuracy)

precision = precision_score(hog_test_label, test_MLP_pred,  average='macro')
print("Precision: ",end = '')
print(precision)

recall = recall_score(hog_test_label, test_MLP_pred,average = 'macro')
print("recall_score: ",end = '')
print(recall)
print()

from sklearn.metrics import confusion_matrix
matrix = confusion_matrix(hog_test_label,test_MLP_pred )

import matplotlib.pyplot as plt
import seaborn as sns

sns.heatmap(matrix,annot=False,cbar=True)

# #ROC and various confusion metrics for CNN
# fpr = dict()
# tpr = dict()
# roc_auc = dict()
# y_score = model_relu.decision_function(test_sample)
# y_tester = np.zeros(np.array(test_label).size)
# for i in range(43):
#   for j in range(len(test_label)):
#     if(test_label[j]==i):
#       y_tester[j] = 1
#     else:
#       y_tester[j] = 0
#   fpr[i],tpr[i],thresh = roc_curve(y_tester,y_score[:,i])
#   roc_auc[i] = auc(fpr[i],tpr[i])
# for i in range(43):
#   plt.plot(fpr[i],tpr[i],label = ("ROC_class :"+str(i)))
# plt.plot([0,1],[0,1],'k--')
# plt.ylabel('True positive rate')
# plt.xlabel('False positive rate')
# plt.title('ROC curve for MLP with RELU with CNN feature')
# plt.show()

from sklearn.ensemble import RandomForestClassifier

random_fr_model = RandomForestClassifier(n_estimators=100, max_depth=50,max_features = 'sqrt')
random_fr_model.fit(hog_train,hog_train_label)

print("for RFR model with ra data")
train_rfr_pred = random_fr_model.predict(hog_train)
accuracy = accuracy_score(hog_train_label, train_rfr_pred)
print("Accuracy on Train: ",end = '')
print(accuracy)

# val_MLP_pred = model_relu.predict(vl_sample)
# accuracy = accuracy_score(vl_label, val_MLP_pred)
# print("Accuracy on val: ",end = '')
# print(accuracy)

test_rfr_pred = model_relu.predict(hog_test)
accuracy = accuracy_score(hog_test_label, test_rfr_pred)
print("Accuracy on test: ",end = '')
print(accuracy)

precision = precision_score(hog_test_label, test_rfr_pred,  average='macro')
print("Precision: ",end = '')
print(precision)

recall = recall_score(hog_test_label, test_rfr_pred,average = 'macro')
print("recall_score: ",end = '')
print(recall)
print()

from sklearn.metrics import confusion_matrix
matrix = confusion_matrix(hog_test_label,test_rfr_pred )

import matplotlib.pyplot as plt
import seaborn as sns

sns.heatmap(matrix,annot=False,cbar=True)

# #ROC and various confusion metrics for CNN
# fpr = dict()
# tpr = dict()
# roc_auc = dict()
# y_score = model_relu.decision_function(test_sample)
# y_tester = np.zeros(np.array(test_label).size)
# for i in range(43):
#   for j in range(len(test_label)):
#     if(test_label[j]==i):
#       y_tester[j] = 1
#     else:
#       y_tester[j] = 0
#   fpr[i],tpr[i],thresh = roc_curve(y_tester,y_score[:,i])
#   roc_auc[i] = auc(fpr[i],tpr[i])
# for i in range(43):
#   plt.plot(fpr[i],tpr[i],label = ("ROC_class :"+str(i)))
# plt.plot([0,1],[0,1],'k--')
# plt.ylabel('True positive rate')
# plt.xlabel('False positive rate')
# plt.title('ROC curve for MLP with RELU with CNN feature')
# plt.show()

print(np.array(htrain).shape)

#Implementing Logistic On raw data, i.e. with no edge extracted features.
from sklearn.linear_model import LogisticRegression
from sklearn import metrics
Train_X_full = []
Test_X_full = []
for i in range(len(filx)):
  a = filx[i].flatten()
  Train_X_full.append(a)
  
for i in range(len(X_test)):
  b = X_test[i].flatten()
  Test_X_full.append(b)

# model_raw = LogisticRegression(solver='lbfgs')
# model_raw.fit(Train_X_full,fily)
# y_pred = model_raw.predict(Test_X_full)
# # how did our model perform?
# count_misclassified = (Y_test != y_pred).sum()
# print('Misclassified samples: {}'.format(count_misclassified))
# accuracy = metrics.accuracy_score(Y_test, y_pred)
# print('Accuracy: {:.2f}'.format(accuracy))

##get the traning acc##
# print(model_raw.score)
y_pred_tr = model_raw.predict(Train_X_full)
accuracy_train = metrics.accuracy_score(fily, y_pred_tr)
print(accuracy_train)

y_pred = model_raw.predict(Test_X_full)

from sklearn.metrics import accuracy_score
from sklearn.metrics import f1_score
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
print("for Logi Raw model")
accuracy = accuracy_score(Y_test, y_pred)
print("Accuracy: ",end = '')
print(accuracy)

precision = precision_score(Y_test, y_pred,  average='macro')
print("Precision: ",end = '')
print(precision)

# f1 = f1_score(y_test,predictions,average = 'macro')
# # print("f1_score: ",end = '')
# # print(f1)

recall = recall_score(Y_test,y_pred,average = 'macro')
print("recall_score: ",end = '')
print(recall)

##ROC Plot Logistic with HOG features
from sklearn.metrics import roc_curve, auc
fpr = dict()
tpr = dict()
roc_auc= dict()
roc = []
for i in range(len(X_test)):
  b = X_test[i].flatten()
  roc.append(b)
y_score = model_raw.decision_function(roc)
#print(y_score.shape)
y_test = np.zeros(len(X_test))
for i in range(43):
    for j in range(len(Y_test)):
        if(Y_test[j]==i):
            y_test[j] = 1
        else:
            y_test[j] = 0
    fpr[i],tpr[i],thresh = roc_curve(y_test,y_score[:,i])
    roc_auc[i] = auc(fpr[i],tpr[i])
for i in (range(43)):
    plt.plot(fpr[i],tpr[i],label=("ROC CLASS :"+str(i)))
plt.plot([0,1],[0,1],'k--')
plt.ylabel('True positive rate')
plt.xlabel('False Positive Rate')
plt.title('ROC curve on RAW features on Logistic')
#plt.legend(loc="lower right")
plt.show()

from sklearn.metrics import confusion_matrix
matrix = confusion_matrix(ts_label,test_MLP_pred )

import matplotlib.pyplot as plt
import seaborn as sns

sns.heatmap(matrix,annot=False,cbar=True)

import pickle
filename = "Logistic_RAW"
pickle.dump(model_raw,open(filename,'wb'))

"""### HOG"""

#Implementing Logistic With Extracted Features from Hog
from sklearn.linear_model import LogisticRegression
from sklearn import metrics
htrain = np.array(htrain)
htest = np.array(htest)
print(htrain.shape)
print(y_train.shape)
print(htest.shape)
print(Y_test.shape)

TrainHog = []
TestHog = []
for i in range(len(htrain)):
  a = htrain[i].flatten()
  TrainHog.append(a)
  
for i in range(len(htest)):
  b = htest[i].flatten()
  TestHog.append(b)

# model_hog = LogisticRegression(solver='lbfgs')
# model_hog.fit(TrainHog,fily)
# y_pred = model_hog.predict(TestHog)
# # how did our model perform?
# count_misclassified = (Y_test != y_pred).sum()
# cnf_matrix = metrics.confusion_matrix(Y_test, y_pred)
# print('Misclassified samples: {}'.format(count_misclassified))
# accuracy = metrics.accuracy_score(Y_test, y_pred)
# print('Accuracy: {:.2f}'.format(accuracy))

y_pred = model_hog.predict(TestHog)

y_pred_tr = model_hog.predict(TrainHog)
accuracy_train = metrics.accuracy_score(fily, y_pred_tr)
print(accuracy_train)

print("for Logi HOG model")
accuracy = accuracy_score(Y_test, y_pred)
print("Accuracy: ",end = '')
print(accuracy)

precision = precision_score(Y_test, y_pred,  average='macro')
print("Precision: ",end = '')
print(precision)

# f1 = f1_score(y_test,predictions,average = 'macro')
# # print("f1_score: ",end = '')
# # print(f1)

recall = recall_score(Y_test,y_pred,average = 'macro')
print("recall_score: ",end = '')
print(recall)

###################ROC FOR HOG FEATURES#########################
##ROC Plot Logistic with HOG features
from sklearn.metrics import roc_curve, auc
fpr = dict()
tpr = dict()
roc_auc= dict()
roc = []
for i in range(len(htest)):
  b = htest[i].flatten()
  roc.append(b)
y_score = model_hog.decision_function(roc)
#print(y_score.shape)
y_test = np.zeros(len(Y_test))
for i in range(43):
    for j in range(len(Y_test)):
        if(Y_test[j]==i):
            y_test[j] = 1
        else:
            y_test[j] = 0
    fpr[i],tpr[i],thresh = roc_curve(y_test,y_score[:,i])
    roc_auc[i] = auc(fpr[i],tpr[i])
for i in (range(43)):
    plt.plot(fpr[i],tpr[i],label=("ROC CLASS :"+str(i)))
plt.plot([0,1],[0,1],'k--')
plt.ylabel('True positive rate')
plt.xlabel('False Positive Rate')
plt.title('ROC curve on HOG features on Logistic')
#plt.legend(loc="lower right")
plt.show()

import pickle
filename = "Logistic_HOG"
pickle.dump(model_raw,open(filename,'wb'))

#Implementing SVM (RBF) with Extracted Features by HOG
from sklearn.svm import SVC
from sklearn import metrics
instance_hog_rbf = SVC(kernel='rbf',gamma='scale')
instance_hog_rbf.fit(TrainHog,fily)
print("HOG SVM RBF")
print("train acc")
tr_acc_pred =  instance_hog_rbf.predict(TrainHog)

import pickle
filename = "SVM_HOG1"
pickle.dump(instance_hog_rbf,open(filename,'wb'))

accuracy_tr = metrics.accuracy_score(fily,tr_acc_pred)
print("accuracy:", accuracy_tr)
y_pred = instance_hog_rbf.predict(TestHog)
accuracy = metrics.accuracy_score(Y_test,y_pred)
print('Accuracy: {:.2f}'.format(accuracy))

print("for SVM HOG model")
accuracy = accuracy_score(Y_test, y_pred)
print("Accuracy: ",end = '')
print(accuracy)

precision = precision_score(Y_test, y_pred,  average='macro')
print("Precision: ",end = '')
print(precision)

# f1 = f1_score(y_test,predictions,average = 'macro')
# # print("f1_score: ",end = '')
# # print(f1)

recall = recall_score(Y_test,y_pred,average = 'macro')
print("recall_score: ",end = '')
print(recall)

"""## ROC FOR SVM HOG FEATURES"""

fpr = dict()
tpr = dict()
roc_auc= dict()
roc = []
for i in range(len(htest)):
  b = htest[i].flatten()
  roc.append(b)
y_score = instance_hog_rbf.decision_function(roc)
#print(y_score.shape)
y_test = np.zeros(len(Y_test))
for i in range(43):
    for j in range(len(Y_test)):
        if(Y_test[j]==i):
            y_test[j] = 1
        else:
            y_test[j] = 0
    fpr[i],tpr[i],thresh = roc_curve(y_test,y_score[:,i])
    roc_auc[i] = auc(fpr[i],tpr[i])
for i in (range(43)):
    plt.plot(fpr[i],tpr[i],label=("ROC CLASS :"+str(i)))
plt.plot([0,1],[0,1],'k--')
plt.ylabel('True positive rate')
plt.xlabel('False Positive Rate')
plt.title('ROC curve on HOG features on SVM  RBF')
#plt.legend(loc="lower right")
plt.show()

#Implementing SVM (RBF) on Raw Data
svm_raw_rbf = SVC(kernel='rbf',gamma='scale')
svm_raw_rbf.fit(Train_X_full,fily)
print("af fitting")
#get the train acc

y_pred_tr = svm_raw_rbf.predict(Train_X_full)
y_pred = svm_raw_rbf.predict(Test_X_full)
accuracy_tr = accuracy_score(fily, y_pred_tr)
print(accuracy_tr,"Acc train")


print("for SVM RAW model")
accuracy = accuracy_score(Y_test, y_pred)
print("Accuracy: ",end = '')
print(accuracy)

precision = precision_score(Y_test, y_pred,  average='macro')
print("Precision: ",end = '')
print(precision)

# f1 = f1_score(y_test,predictions,average = 'macro')
# # print("f1_score: ",end = '')
# # print(f1)

recall = recall_score(Y_test,y_pred,average = 'macro')
print("recall_score: ",end = '')
print(recall)

###PICKLE THE FILE ####
filename = "SVM_RAW_RBF"
pickle.dump(svm_raw_rbf,open(filename,'wb'))

####ROC FOR RAW######
fpr = dict()
tpr = dict()
roc_auc= dict()
roc = []
for i in range(len(X_test)):
  b = X_test[i].flatten()
  roc.append(b)
y_score = svm_raw_rbf.decision_function(roc)
#print(y_score.shape)
y_test = np.zeros(len(X_test))
for i in range(43):
    for j in range(len(Y_test)):
        if(Y_test[j]==i):
            y_test[j] = 1
        else:
            y_test[j] = 0
    fpr[i],tpr[i],thresh = roc_curve(y_test,y_score[:,i])
    roc_auc[i] = auc(fpr[i],tpr[i])
for i in (range(43)):
    plt.plot(fpr[i],tpr[i],label=("ROC CLASS :"+str(i)))
plt.plot([0,1],[0,1],'k--')
plt.ylabel('True positive rate')
plt.xlabel('False Positive Rate')
plt.title('ROC curve on RAW features on Logistic')
#plt.legend(loc="lower right")
plt.show()

#Implementing SVM (Poly3) with Extracted Features by HOG
from sklearn.svm import SVC
from sklearn import metrics
svm_poly_hog = SVC(kernel='poly',degree=3)
svm_poly_hog.fit(TrainHog,fily)
tr_acc_pred =  svm_poly_hog.predict(TrainHog)
accuracy_train = metrics.accuracy_score(fily,tr_acc_pred)
print("af fitting")
print("training accu on POLY HOG:", accuracy_train)
y_pred = svm_poly_hog.predict(TestHog)
accuracy = metrics.accuracy_score(Y_test,y_pred)
print('Accuracy: {:.2f}'.format(accuracy))
precision = precision_score(Y_test, y_pred,  average='macro')
print("Precision: ",end = '')
print(precision)

# f1 = f1_score(y_test,predictions,average = 'macro')
# # print("f1_score: ",end = '')
# # print(f1)

recall = recall_score(Y_test,y_pred,average = 'macro')
print("recall_score: ",end = '')
print(recall)



filename = "SVM_HOG_Poly"
pickle.dump(svm_poly_hog,open(filename,'wb'))

###ROC 
from sklearn.metrics import roc_curve, auc
from sklearn.metrics import roc_auc_score
fpr = dict()
tpr = dict()
roc_auc= dict()
roc = []
for i in range(len(htest)):
  b = htest[i].flatten()
  roc.append(b)
y_score = svm_poly_hog.decision_function(roc)
#print(y_score.shape)
y_test = np.zeros(len(Y_test))
for i in range(43):
    for j in range(len(Y_test)):
        if(Y_test[j]==i):
            y_test[j] = 1
        else:
            y_test[j] = 0
    fpr[i],tpr[i],thresh = roc_curve(y_test,y_score[:,i])
    roc_auc[i] = auc(fpr[i],tpr[i])
for i in (range(43)):
    plt.plot(fpr[i],tpr[i],label=("ROC CLASS :"+str(i)))
plt.plot([0,1],[0,1],'k--')
plt.ylabel('True positive rate')
plt.xlabel('False Positive Rate')
plt.title('ROC curve on HOG features on SVM  poly')
#plt.legend(loc="lower right")
plt.show()

####not now
pickle.dump(filename = "SVM_RAW_Poly"
pickle.dump(svm_po_raw,open(filename,'wb')),open(filename,'wb'))

#Implementing SVM (Poly3) on Raw Data
###not now
sum_po_raw = SVC(kernel='poly',degree=3)
sum_po_raw.fit(Train_X_full,y_train)
print("SVM poly3 RAW")
y_pred_acc = sum_po_raw.predict(Train_X_full)
accuracy = metrics.accuracy_score(Y_test,y_pred_acc)
print("training acc on SVM POLY3", accuracy)
print('Accuracy: {:.2f}'.format(accuracy))
print("for SVM HOG model")
accuracy = accuracy_score(Y_test, y_pred)
print("Accuracy: ",end = '')
print(accuracy)

precision = precision_score(Y_test, y_pred,  average='macro')
print("Precision: ",end = '')
print(precision)

# f1 = f1_score(y_test,predictions,average = 'macro')
# # print("f1_score: ",end = '')
# # print(f1)

recall = recall_score(Y_test,y_pred,average = 'macro')
print("recall_score: ",end = '')
print(recall)

###ROC
###not now
fpr = dict()
tpr = dict()
roc_auc= dict()
roc = []
for i in range(len(X_test)):
  b = X_test[i].flatten()
  roc.append(b)
y_score = sum_po_raw.decision_function(roc)
#print(y_score.shape)
y_test = np.zeros(len(X_test))
for i in range(43):
    for j in range(len(Y_test)):
        if(Y_test[j]==i):
            y_test[j] = 1
        else:
            y_test[j] = 0
    fpr[i],tpr[i],thresh = roc_curve(y_test,y_score[:,i])
    roc_auc[i] = auc(fpr[i],tpr[i])
for i in (range(43)):
    plt.plot(fpr[i],tpr[i],label=("ROC CLASS :"+str(i)))
plt.plot([0,1],[0,1],'k--')
plt.ylabel('True positive rate')
plt.xlabel('False Positive Rate')
plt.title('ROC curve on RAW features on SVM POLY3')
#plt.legend(loc="lower right")
plt.show()

#Implementing SVM (Linear) with Extracted Features by HOG
from sklearn.svm import SVC
from sklearn import metrics
instance = SVC(kernel='linear',C=0.001,gamma=0.001)
instance.fit(TrainHog,fily)
print("af fitting")
y_pred_tra = instance.predict(TrainHog)
tra_acc = metrics.accuracy_score(fily,y_pred_tra)
print("traning acc:", tra_acc)
y_pred = instance.predict(TestHog)
accuracy = metrics.accuracy_score(Y_test,y_pred)
print('Accuracy: {:.2f}'.format(accuracy))

precision = precision_score(Y_test, y_pred,  average='macro')
print("Precision: ",end = '')
print(precision)

# f1 = f1_score(y_test,predictions,average = 'macro')
# # print("f1_score: ",end = '')
# # print(f1)

recall = recall_score(Y_test,y_pred,average = 'macro')
print("recall_score: ",end = '')
print(recall)

from sklearn.metrics import accuracy_score
from sklearn.metrics import f1_score
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
precision = precision_score(Y_test, y_pred,  average='macro')
print("Precision: ",end = '')
print(precision)

# f1 = f1_score(y_test,predictions,average = 'macro')
# # print("f1_score: ",end = '')
# # print(f1)

recall = recall_score(Y_test,y_pred,average = 'macro')
print("recall_score: ",end = '')
print(recall)

import pickle
filename = "SVM_HOG_Linear"
pickle.dump(instance,open(filename,'wb'))

###ROC 
fpr = dict()
tpr = dict()
roc_auc= dict()
roc = []
for i in range(len(htest)):
  b = htest[i].flatten()
  roc.append(b)
y_score = instance.decision_function(roc)
#print(y_score.shape)
y_test = np.zeros(len(Y_test))
for i in range(43):
    for j in range(len(Y_test)):
        if(Y_test[j]==i):
            y_test[j] = 1
        else:
            y_test[j] = 0
    fpr[i],tpr[i],thresh = roc_curve(y_test,y_score[:,i])
    roc_auc[i] = auc(fpr[i],tpr[i])
for i in (range(43)):
    plt.plot(fpr[i],tpr[i],label=("ROC CLASS :"+str(i)))
plt.plot([0,1],[0,1],'k--')
plt.ylabel('True positive rate')
plt.xlabel('False Positive Rate')
plt.title('ROC curve on HOG features on SVM  linear')
#plt.legend(loc="lower right")
plt.show()

#Implementing SVM (RBF) with Extracted Features by HOG and Tuned Params
# from sklearn.svm import SVC
# from sklearn import metrics
# instance = SVC(kernel='rbf',gamma=0.001,C=0.001)
# instance.fit(TrainHog,y_train)
# print("af fitting")
# y_pred = instance.predict(TestHog)
# accuracy = metrics.accuracy_score(Y_test,y_pred)
# print('Accuracy: {:.2f}'.format(accuracy))

plt.imshow(hog_image)
plt.show()

# starting with CNN
import torch
from torch.nn import ReLU, Conv2d, Linear, Sequential, MaxPool2d, Module, Dropout 


train_x = np.array(filx)
train_y = np.array(fily)
print(train_x.shape)
print(train_y.shape)

class CNN_model(Moule):
  
  def __init__(self):
    super(CNN_model,self).__init__()
    # image 32,32,1
    self.layer1 = Sequential(
      Conv2d(1,16,kernel_size=3,stride=1,padding=0),
      ReLU(),
      MaxPool2d(kernel_size=2,stride=2),
      Dropout(p = 0.3))
    # image 15,15,16
    self.layer2 = Sequential(
      Conv2d(16,32,kernel_size=3,stride=1,padding=1),
      ReLU(),
      MaxPool2d(kernel_size=2,stride=2),
      Dropout(p = 0.2))
    #image 7,7,32
    self.layer3 = Sequential(
      Conv2d(32,64,kernel_size=3,stride=1,padding=1),
      ReLU(),
      MaxPool2d(kernel_size=2,stride=2),
      Dropout(p = 0.1))
    # image 3,3,64
    
    #Now adding fully connected network in CNN
    self.fullyC1 = Linear(3*3*64, 84, bias=True)
    torch.nn.init.xavier_uniform(self.fullyC1.weight) #initialize parameters
    self.layer4 = Sequential(self.fullYC1,ReLU())

# Baseline Model
# Logistic Regression
from sklearn.model_selection import train_test_split,learning_curve
from sklearn.linear_model import LogisticRegression
from sklearn import metrics
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
np.set_printoptions(threshold=np.inf)

X = filx
Y = fily
TestX=data_gray['x_test']
TestY=data_gray['y_test']
Training_X = []
Testing_X = []
Training_Y = []
Testing_Y = []

trX = np.array(X)
teX = np.array(ex_test)
print(trX.shape)

for i in range(len(X)):
  a = trX[i].flatten()
  Training_X.append(a)
  
for i in range(len(teX)):
  b = teX[i].flatten()
  Testing_X.append(b)
  
#X_Train, X_Test, Y_Train, Y_Test = train_test_split(Training_X,Y,test_size=0.2,random_state=0)
#model = LogisticRegression(solver = 'lbfgs')
model = LogisticRegression(solver='lbfgs')
model.fit(Training_X,Y)
y_pred = model.predict(Testing_X)
# how did our model perform?
count_misclassified = (TestY != y_pred).sum()
cnf_matrix = metrics.confusion_matrix(TestY, y_pred)
print('Misclassified samples: {}'.format(count_misclassified))
accuracy = metrics.accuracy_score(TestY, y_pred)
print('Accuracy: {:.2f}'.format(accuracy)) 
print(cnf_matrix)



## Fit SVM
from sklearn.svm import SVC
from sklearn import metrics
from sklearn.metrics import auc
import matplotlib.pyplot as plt
print("after data")

X = filx
Y = fily
TestX=data_gray['x_test']
TestY=data_gray['y_test']
Training_X = []
Testing_X = []
Training_Y = []
Testing_Y = []

trX = np.array(X)
teX = np.array(TestX)
print(trX.shape)

for i in range(len(X)):
  a = trX[i].flatten()
  Training_X.append(a)
  
for i in range(len(teX)):
  b = teX[i].flatten()
  Testing_X.append(b)
  
instance = SVC(kernel='rbf',gamma='scale')
instance.fit(Training_X,Y)
print("af fitting")
y_pred = instance.predict(Testing_X)
accuracy = metrics.accuracy_score(TestY,y_pred)
print('Accuracy: {:.2f}'.format(accuracy))

from sklearn.metrics import roc_curve
from sklearn.metrics import roc_auc_score

#ROC curve
fpr = dict()
tpr = dict()
roc_auc= dict()
y_score = instance.decision_function(Testing_X)
#print(y_score.shape)
y_test = np.zeros(TestY.size)
for i in range(43):
    for j in range(len(TestY)):
        if(TestY[j]==i):
            y_test[j] = 1
        else:
            y_test[j] = 0
    fpr[i],tpr[i],thresh = roc_curve(y_test,y_score[:,i])
    roc_auc[i] = auc(fpr[i],tpr[i])
for i in (range(43)):
    plt.plot(fpr[i],tpr[i],label=("ROC CLASS :"+str(i)))
plt.plot([0,1],[0,1],'k--')
plt.ylabel('True positive rate')
plt.xlabel('False Positive Rate')
plt.title('ROC curve for SVM_nokernel_fold1_ovr_model')
#plt.legend(loc="lower right")
plt.show()

from sklearn.metrics import roc_curve
from sklearn.metrics import roc_auc_score
from sklearn.metrics import auc

#ROC curve
fpr = dict()
tpr = dict()
roc_auc= dict()
y_score = instance.decision_function(Testing_X)
#print(y_score.shape)
y_test = np.zeros(TestY.size)
for i in range(43):
    for j in range(len(TestY)):
        if(TestY[j]==i):
            y_test[j] = 1
        else:
            y_test[j] = 0
    fpr[i],tpr[i],thresh = roc_curve(y_test,y_score[:,i])
    roc_auc[i] = auc(fpr[i],tpr[i])
for i in (range(43)):
    plt.plot(fpr[i],tpr[i],label=("ROC CLASS :"+str(i)))
plt.plot([0,1],[0,1],'k--')
plt.ylabel('True positive rate')
plt.xlabel('False Positive Rate')
plt.title('ROC curve for SVM_nokernel_fold1_ovr_model')
#plt.legend(loc="lower right")
plt.show()

#This would be used for tuning gamma and C for SVM
from sklearn import svm
from sklearn.model_selection import GridSearchCV
def svc_param_selection(X, y, nfolds):
    Cs = [0.001, 0.01, 0.1, 1, 10]
    gammas = [0.001, 0.01, 0.1, 1]
    param_grid = {'C': Cs, 'gamma' : gammas}
    grid_search = GridSearchCV(svm.SVC(kernel='rbf'), param_grid, cv=nfolds)
    grid_search.fit(X, y)
    grid_search.best_params_
    return grid_search.best_params_

bestparams = svc_param_selection(Training_X,Y,5)
print(bestparams)

from sklearn.svm import SVC
from sklearn import metrics
from sklearn.metrics import auc
import matplotlib.pyplot as plt
print("after data")
X = filx
Y = fily
TestX=data_gray['x_test']
TestY=data_gray['y_test']
Training_X = []
Testing_X = []
Training_Y = []
Testing_Y = []

trX = np.array(X)
teX = np.array(TestX)
print(trX.shape)

for i in range(len(X)):
  a = trX[i].flatten()
  Training_X.append(a)
  
for i in range(len(teX)):
  b = teX[i].flatten()
  Testing_X.append(b)
instance = SVC(kernel='poly',degree=3)
instance.fit(Training_X,Y)
y_pred = instance.predict(Testing_X)
accuracy = metrics.accuracy_score(TestY,y_pred)
print('Accuracy: {:.2f}'.format(accuracy))
from sklearn.metrics import roc_curve
from sklearn.metrics import roc_auc_score

#ROC curve
fpr = dict()
tpr = dict()
roc_auc= dict()
y_score = instance.decision_function(Testing_X)
#print(y_score.shape)
y_test = np.zeros(TestY.size)
for i in range(43):
    for j in range(len(TestY)):
        if(TestY[j]==i):
            y_test[j] = 1
        else:
            y_test[j] = 0
    fpr[i],tpr[i],thresh = roc_curve(y_test,y_score[:,i])
    roc_auc[i] = auc(fpr[i],tpr[i])
for i in (range(43)):
    plt.plot(fpr[i],tpr[i],label=("ROC CLASS :"+str(i)))
plt.plot([0,1],[0,1],'k--')
plt.ylabel('True positive rate')
plt.xlabel('False Positive Rate')
plt.title('ROC curve for SVM_nokernel_fold1_ovr_model')
#plt.legend(loc="lower right")
plt.show()

from sklearn.svm import SVC
from sklearn import metrics
from sklearn.metrics import auc
import matplotlib.pyplot as plt
instance = SVC(kernel='linear')
instance.fit(Training_X,Y)
y_pred = instance.predict(Testing_X)
accuracy = metrics.accuracy_score(TestY,y_pred)
print('Accuracy: {:.2f}'.format(accuracy))
from sklearn.metrics import roc_curve
from sklearn.metrics import roc_auc_score

#ROC curve
fpr = dict()
tpr = dict()
roc_auc= dict()
y_score = instance.decision_function(Testing_X)
#print(y_score.shape)
y_test = np.zeros(TestY.size)
for i in range(43):
    for j in range(len(TestY)):
        if(TestY[j]==i):
            y_test[j] = 1
        else:
            y_test[j] = 0
    fpr[i],tpr[i],thresh = roc_curve(y_test,y_score[:,i])
    roc_auc[i] = auc(fpr[i],tpr[i])
for i in (range(43)):
    plt.plot(fpr[i],tpr[i],label=("ROC CLASS :"+str(i)))
plt.plot([0,1],[0,1],'k--')
plt.ylabel('True positive rate')
plt.xlabel('False Positive Rate')
plt.title('ROC curve for SVM_nokernel_fold1_ovr_model')
#plt.legend(loc="lower right")
plt.show()

#Function for convolution without zero padding
import numpy as np
import matplotlib.pyplot as plt
#A function to show TYPE of IMAGE with their CUSTOM LABEL TAG!
def image_dikhao(X,Y):
  #get the unique labels from Y
  uy = np.unique(Y)
  c= [] 
  plt.figure(figsize = (15, 15))
  
  for i in range(len(uy)):
    c.append(0)
  k = 1
  for i in range(len(X)):
    if(c[Y[i]]==0):
      #this is a new data 
      c[Y[i]]+=1

      plt.subplot(8,8,k)
      plt.axis('off')
      k+=1

      plt.title("label: "+str(Y[i]))

      temp = X[i][0]
      _ = plt.imshow(temp)

  plt.show()

image_dikhao(X,Y)
  


      
  #now run from the dataX and plot the first data

from sklearn.svm import SVC
from sklearn import metrics
from sklearn.metrics import auc
import matplotlib.pyplot as plt
X = filx
Y = fily
TestX=data_gray['x_test']
TestY=data_gray['y_test']
Training_X = []
Testing_X = []
Training_Y = []
Testing_Y = []

trX = np.array(X)
teX = np.array(TestX)

for i in range(len(X)):
  a = trX[i].flatten()
  Training_X.append(a)
  
for i in range(len(teX)):
  b = teX[i].flatten()
  Testing_X.append(b)
  
instance = SVC(kernel='linear')
instance.fit(Training_X,Y)
y_pred = instance.predict(Testing_X)
accuracy = metrics.accuracy_score(TestY,y_pred)
print('Accuracy: {:.2f}'.format(accuracy))
from sklearn.metrics import roc_curve
from sklearn.metrics import roc_auc_score

import matplotlib.pyplot as plt
print("after data")



#ROC curve
fpr = dict()
tpr = dict()
roc_auc= dict()
y_score = instance.decision_function(Testing_X)
#print(y_score.shape)
y_test = np.zeros(TestY.size)
for i in range(43):
    for j in range(len(TestY)):
        if(TestY[j]==i):
            y_test[j] = 1
        else:
            y_test[j] = 0
    fpr[i],tpr[i],thresh = roc_curve(y_test,y_score[:,i])
    roc_auc[i] = auc(fpr[i],tpr[i])
for i in (range(43)):
    plt.plot(fpr[i],tpr[i],label=("ROC CLASS :"+str(i)))
plt.plot([0,1],[0,1],'k--')
plt.ylabel('True positive rate')
plt.xlabel('False Positive Rate')
plt.title('ROC curve for SVM_nokernel_fold1_ovr_model')
#plt.legend(loc="lower right")
plt.show()

fpr = dict()
tpr = dict()
roc_auc= dict()
y_score = instance.decision_function(Testing_X)
#print(y_score.shape)
y_test = np.zeros(TestY.size)
for i in range(43):
    for j in range(len(TestY)):
        if(TestY[j]==i):
            y_test[j] = 1
        else:
            y_test[j] = 0
    fpr[i],tpr[i],thresh = roc_curve(y_test,y_score[:,i])
    roc_auc[i] = auc(fpr[i],tpr[i])
for i in (range(43)):
    plt.plot(fpr[i],tpr[i],label=("ROC CLASS :"+str(i)))
plt.plot([0,1],[0,1],'k--')
plt.ylabel('True positive rate')
plt.xlabel('False Positive Rate')
plt.title('ROC curve for SVM_nokernel_fold1_ovr_model')
#plt.legend(loc="lower right")
plt.show()